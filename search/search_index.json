{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Open the AI Context Window with UltraRepo","text":""},{"location":"#got-massive-code-or-document-archives","title":"Got Massive Code or Document Archives?","text":"<p>UltraRepo RAG builds advanced Knowledge Graphs from your source code, documents, or unstructured data \u2014  giving AI Agents the context they need to rapidly learn, infer and to reason intelligently. Open the AI Context Window to infinity and beyond! </p> <p>No need to upload gigabytes of code into LLM memory \u2014 let Graph RAG do the heavy lifting.</p>"},{"location":"#why-choose-ultrarepo-rag","title":"Why Choose UltraRepo RAG?","text":"<ul> <li>\u2728 AI Agent Discoverable Code, Content, Data provides accuracy with no limits</li> <li>\ud83d\udce6 Graph RAG transforms code, docs, and data into an intelligent knowledge base  </li> <li>\ud83e\udde0 Optimized for hybrid symbolic + semantic search with <code>Neo4j</code> and <code>Qdrant</code> </li> <li>\ud83d\udd10 Local, secure, and offline-ready for privacy-sensitive applications</li> </ul> <p>For more information, visit UltraRepo.com</p>"},{"location":"index-old/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"index-old/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"index-old/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"Getting%20Started/1-Intro/getting-started/","title":"Getting Started","text":"<p>Welcome to the UltraRepo Graph RAG project! Follow these steps to get up and running:</p>"},{"location":"Getting%20Started/1-Intro/getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/UltraRepo/graph-rag.git\ncd graph-rag\n</code></pre>"},{"location":"Getting%20Started/1-Intro/getting-started/#2-install-dependencies","title":"2. Install Dependencies","text":"<p>Make sure you have Python and pip installed. Then run:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"Getting%20Started/1-Intro/getting-started/#3-start-the-server","title":"3. Start the Server","text":"<pre><code>uvicorn src.main:app --reload\n</code></pre> <p>You're ready to go!</p>"},{"location":"Getting%20Started/1-Intro/project_docs/","title":"LLM Knowledge Graph Builder","text":""},{"location":"Getting%20Started/1-Intro/project_docs/#introduction","title":"Introduction","text":"<p>This document provides comprehensive documentation for the Neo4j llm-graph-builder Project, a Python web application built with the FastAPI framework. It covers various aspects of the project, including its features, architecture, usage, development, deployment, limitations and known issues.</p>"},{"location":"Getting%20Started/1-Intro/project_docs/#features","title":"Features","text":"<ul> <li>Upload unstructured data from multiple sources to generate structuted Neo4j knowledge graph.</li> <li>Extraction of nodes and relations from multiple LLMs(OpenAI GPT-3.5, OpenAI GPT-4, Gemini 1.0-Pro and Diffbot).</li> <li>View complete graph or only a particular element of graph(ex: Only chunks, only entities, document and entities, etc.) </li> <li>Generate embedding of chunks created from unstructured content.</li> <li>Generate k-nearest neighbors graph for similar chunks.</li> <li>Chat with graph data using chat bot.</li> </ul>"},{"location":"Getting%20Started/1-Intro/project_docs/#local-setup-and-execution","title":"Local Setup and Execution","text":"<p>Run Docker Compose to build and start all components: <pre><code>docker-compose up --build\n</code></pre></p> <p>Alternatively, run specific directories separately:</p> <p>For frontend <pre><code>cd frontend\nyarn\nyarn run dev\n</code></pre></p> <p>For backend <pre><code>cd backend\npython -m venv envName\nsource envName/bin/activate \npip install -r requirements.txt\nuvicorn score:app --reload\n</code></pre></p> <p>Set up environment variables: <pre><code>OPENAI_API_KEY = \"\"\nDIFFBOT_API_KEY = \"\"\nNEO4J_URI = \"\"\nNEO4J_USERNAME = \"\"\nNEO4J_PASSWORD = \"\"\nNEO4J_DATABASE = \"\"\nAWS_ACCESS_KEY_ID =  \"\"\nAWS_SECRET_ACCESS_KEY = \"\"\nEMBEDDING_MODEL = \"\"\nIS_EMBEDDING = \"TRUE\"\nKNN_MIN_SCORE = \"\"\nLANGCHAIN_API_KEY = \"\"\nLANGCHAIN_PROJECT = \"\"\nLANGCHAIN_TRACING_V2 = \"\"\nLANGCHAIN_ENDPOINT = \"\"\nNUMBER_OF_CHUNKS_TO_COMBINE = \"\"\n</code></pre></p>"},{"location":"Getting%20Started/1-Intro/project_docs/#architecture","title":"Architecture","text":""},{"location":"Getting%20Started/1-Intro/project_docs/#development","title":"Development","text":""},{"location":"Getting%20Started/1-Intro/project_docs/#backend","title":"Backend","text":"<p>Backend Documentation</p>"},{"location":"Getting%20Started/1-Intro/project_docs/#frontend","title":"Frontend","text":"<p>Frontend Documentation</p>"},{"location":"Getting%20Started/1-Intro/project_docs/#deployment-and-monitoring","title":"Deployment and Monitoring","text":"<ul> <li>The application is deployed on Google Cloud Platform.</li> </ul> <p>To deploy frontend: <pre><code>gcloud run deploy \nsource location current directory &gt; Frontend\nregion : 32 [us-central 1]\nAllow unauthenticated request : Yes\n</code></pre></p> <p>To deploy backend: <pre><code>gcloud run deploy --set-env-vars \"OPENAI_API_KEY = \" --set-env-vars \"DIFFBOT_API_KEY = \" --set-env-vars \"NEO4J_URI = \" --set-env-vars \"NEO4J_PASSWORD = \" --set-env-vars \"NEO4J_USERNAME = \"\nsource location current directory &gt; Backend\nregion : 32 [us-central 1]\nAllow unauthenticated request : Yes\n</code></pre></p> <ul> <li>Langserve is used with FAST API to deploy Langchain runnables and chains as a REST API.</li> <li>Langsmith is used to monitor and evaluate the application</li> </ul> <p>Development url: [TBD]</p> <p>Production url: [TBD]</p>"},{"location":"Getting%20Started/1-Intro/project_docs/#appendix","title":"Appendix","text":""},{"location":"Getting%20Started/1-Intro/project_docs/#limitations","title":"Limitations","text":"<ul> <li>Only pdf file uploaded from device or uploaded from s3 bucket or gcs bucket can be processed.</li> <li>GCS buckets present under 1051503595507@cloudbuild.gserviceaccount.com service account can only be accessed.</li> <li>Only 1<sup>st</sup> page of Wikipedia content is processed to generate graphDocument.</li> </ul>"},{"location":"Getting%20Started/1-Intro/project_docs/#known-issues","title":"Known issues","text":"<ul> <li>InactiveRpcError error with Gemini 1.0 Pro -  grpc_status:13, grpc_message:\"Internal error encountered.\"</li> <li>ResourceExhausted error with Gemini 1.5 Pro - 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro</li> <li>Gemini response validation errors even after making safety_settings parameters to BLOCK_NONE. </li> </ul>"},{"location":"Getting%20Started/2-Config/","title":"UltraRepo Graph RAG","text":"<p>Online Docs:  https://UltraRepo.github.io/graph-rag/</p>"},{"location":"Getting%20Started/2-Config/#problem-overview","title":"\ud83d\udd0d Problem Overview","text":"<p>AI Agents and systems have a limited context window (typically &lt;2M tokens), which prevents them from ingesting and reasoning over large codebases, datasets, and document archives in one pass. This context window limitation restricts the AI\u2019s ability to provide accurate answers across an entire repository, whether its code, docs or data.</p>"},{"location":"Getting%20Started/2-Config/#solution-overview","title":"\ud83d\udca1 Solution Overview","text":"<p>Unlike basic RAG solutions that lack a knowledge graph to 'map' content for discoverability by AI, UltraRepo Graph RAG combines the power of RAG with the intelligence, accuracy and AI discoverability offered by a knowledge graph (KG). Lightweight metadata indexing is provided by the KG via the Neo4j graph database, and vector data is stored independently in a scalable, searchable vector DB such as Qdrant, Weaviate, Pinecone or others. Private AI is offered through the a self-hosted LLM option with Ollama; online LLMs are also available for use in retrieval and processing. Save time when working with LLMs and get better accuracy.  Instead of requiring full content uploads during chat sessions with limited content windows, UltraRepo Graph Rag helps you by scanning repo files, then processing and embedding the repo source files into your vector DB, and then links these source files using the UltraRepo Graph, which is a'map' to your content items.  Content such as blobs and files can be stored separately in a separate database, in a git worktree, or as simple files/folders in a filesystem.</p> <p>Our objective is to provide an open source project that has offers smart AI-powered understanding and retrieval of content from massive software and document repositories, regardless of context window size, across multiple LLMs, both private and public, to both AI Agents and human operated AI Chat clients.  With UltraRepo Graph Rag,  improving LLM reasoning, traceability, and extensibility.</p> <p>File Type Support:  Initially support is provided for text files and PDF files.  </p> <p>Repo File, DB Scanning:  This project has basic file uploads of repo files to the Graph Rag server. If you need repo file and DB scanning with KG and smart classification and embedding, checkout UltraRepo's commercial version (coming soon!) at UltraRepo.com.</p>"},{"location":"Getting%20Started/2-Config/#project-overview","title":"\ud83d\ude80 Project Overview","text":"<p>UltraRepo Graph RAG is based on the open source Neo4j LLM Graph Builder, with added support for:</p> <ul> <li>Advanced Graph RAG processing</li> <li>Smart Code/Data indexing for AI Agents</li> <li>Qdrant vector search integration</li> <li>Rich FastAPI backends</li> <li>Full MkDocs Material documentation support</li> </ul> <p>This project forms the backend engine of a \u201csmart repository\u201d designed for use with local, hybrid, or cloud-based AI Agents.</p>"},{"location":"Getting%20Started/2-Config/#installation-mkdocs-material-theme","title":"\ud83d\udce6 Installation: MkDocs &amp; Material Theme","text":""},{"location":"Getting%20Started/2-Config/#1-setup-virtual-environment","title":"1\ufe0f\u20e3 Setup Virtual Environment","text":"<pre><code>python -m venv .venv\nsource .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n</code></pre>"},{"location":"Getting%20Started/2-Config/#2-install-dependencies","title":"2\ufe0f\u20e3 Install Dependencies","text":"<pre><code>pip install mkdocs-material\npip install mkdocs-git-revision-date-localized-plugin\npip install mkdocs-minify-plugin\n</code></pre>"},{"location":"Getting%20Started/2-Config/#3-sample-mkdocsyml-configuration","title":"3\ufe0f\u20e3 Sample <code>mkdocs.yml</code> Configuration","text":"<pre><code>site_name: UltraRepo-Graph-RAG Documentation\ntheme:\n  name: material\n  features:\n    - navigation.tabs\n    - search.highlight\n    - content.code.copy\nplugins:\n  - search\n  - git-revision-date-localized\n  - minify\nmarkdown_extensions:\n  - admonition\n  - codehilite\n  - footnotes\n  - pymdownx.superfences\n  - toc:\n      permalink: true\n</code></pre> <p>Recommended MkDocs Material theme plugins to install <pre><code>pip install \\\n  mkdocs-material \\\n  mkdocs-minify-plugin \\\n  mkdocs-git-revision-date-localized-plugin \\\n  mkdocs-glightbox \\\n  pymdown-extensions\n  ```\n\n\n### 4\ufe0f\u20e3 Serve Docs\n\n```bash\nmkdocs serve\n# Open http://127.0.0.1:8000\n</code></pre></p>"},{"location":"Getting%20Started/2-Config/#repo-structure-derived-from-llm-graph-builder","title":"\ud83d\udcc1 Repo Structure (derived from llm-graph-builder)","text":"<pre><code>[ultrarepo-graph-rag/](https://github.com/UltraRepo/graph-rag/)\n- `ultrarepo-graph-rag/`: Root of the UltraRepo Graph-RAG project\n- `\u251c\u2500\u2500 LICENSE`: License file (MIT or similar)\n- `\u251c\u2500\u2500 README.md`: Main project documentation and overview\n- `\u251c\u2500\u2500 data/`: Sample files and PDF input data for ingestion\n- `\u251c\u2500\u2500 docs/`: Markdown documentation for MkDocs site\n- `\u251c\u2500\u2500 mkdocs.yml`: Configuration file for MkDocs Material documentation site\n- `\u251c\u2500\u2500 src/`: Primary application source code directory\n- `\u2502   \u251c\u2500\u2500 backend/`: FastAPI backend server logic\n- `\u2502   \u2502   \u251c\u2500\u2500 api/`: API initialization and launch code\n- `\u2502   \u2502   \u251c\u2500\u2500 utils/`: Utility functions and helper modules\n- `\u2502   \u251c\u2500\u2500 constants/`: Global constants used across services\n- `\u2502   \u251c\u2500\u2500 embeddings/`: Embedding model classes (OpenAI, SentenceTransformers, etc.)\n- `\u2502   \u251c\u2500\u2500 graph_generation/`: Graph schema and graph extraction logic\n- `\u2502   \u2502   \u251c\u2500\u2500 graph_generation.py`: Transforms input text into nodes and relationships\n- `\u2502   \u2502   \u251c\u2500\u2500 make_relationships.py`: Creates/refines relationships between graph nodes\n- `\u2502   \u251c\u2500\u2500 models/`: Pydantic models for FastAPI request/response validation\n- `\u2502   \u251c\u2500\u2500 post_processing/`: KNN graph linking and full-text indexing\n- `\u2502   \u2502   \u251c\u2500\u2500 post_processing.py`: Similarity vector linking, KNN construction\n- `\u2502   \u251c\u2500\u2500 retrievers/`: Vector and hybrid retrieval logic (Neo4j + Qdrant)\n- `\u2502   \u251c\u2500\u2500 routers/`: FastAPI endpoints and route logic\n- `\u2502   \u2502   \u251c\u2500\u2500 chat.py`: Handles chat endpoints and response orchestration\n- `\u2502   \u2502   \u251c\u2500\u2500 connection.py`: Neo4j DB connection handlers\n- `\u2502   \u2502   \u251c\u2500\u2500 documents.py`: APIs to handle document scanning and ingestion\n- `\u2502   \u2502   \u251c\u2500\u2500 upload.py`: Chunked file upload endpoint logic\n- `\u2502   \u251c\u2500\u2500 schemas/`: Custom schema templates for entities and relationships\n- `\u2502   \u251c\u2500\u2500 services/`: Business logic for API endpoints\n- `\u2502   \u251c\u2500\u2500 types/`: Typed definitions, enums, data classes\n- `\u251c\u2500\u2500 tests/`: Unit and integration test cases\n</code></pre> <ul> <li><code>\ud83d\udcdd Key Backend Modules</code>: </li> <li>\u2022 graphDB_dataAccess.py: Located in <code>src/backend/api/</code> - Handles raw database operations and queries</li> <li>\u2022 graph_generation.py: Located in <code>src/graph_generation/</code> - Generates GraphDocument representations from LLM</li> <li>\u2022 make_relationships.py: Located in <code>src/graph_generation/</code> - Refines node/edge creation and schema matching</li> <li>\u2022 post_processing.py: Located in <code>src/post_processing/</code> - Handles KNN vector linkages and post graph cleanup</li> </ul>"},{"location":"Getting%20Started/2-Config/#documentation-and-extensibility","title":"\ud83d\udcda Documentation and Extensibility","text":"<p>UltraRepo Graph RAG is fully compatible with MkDocs Material, making it easy to extend with internal documentation, tagging, search, and AI-ready summaries.</p> <p>For more details on how to use GraphRAG with Neo4j, Qdrant, and LangChain, visit: \ud83d\udc49 https://neo4j.com/docs/neo4j-graphrag-python/current/</p>"},{"location":"Getting%20Started/2-Config/#knowledge-graph-builder-app","title":"Knowledge Graph Builder App","text":"<p>The following details provide background and installation info for the knowledge graph builder app.  This info is provided courtesy of Neo4j's Graph RAG project team.  The Neo4j Graph Rag project is an open source, MIT project that provides knowledge graphs from unstructured data.</p>"},{"location":"Getting%20Started/2-Config/#llm-graph-builder","title":"LLM Graph Builder","text":""},{"location":"Getting%20Started/2-Config/#overview","title":"Overview","text":"<p>This application is designed to turn Unstructured data (pdfs,docs,txt,youtube video,web pages,etc.) into a knowledge graph stored in Neo4j. It utilizes the power of Large language models (OpenAI,Gemini,etc.) to extract nodes, relationships and their properties from the text and create a structured knowledge graph using Langchain framework. </p> <p>Upload your files from local machine, GCS or S3 bucket or from web sources, choose your LLM model and generate knowledge graph.</p>"},{"location":"Getting%20Started/2-Config/#key-features","title":"Key Features","text":"<ul> <li>Knowledge Graph Creation: Transform unstructured data into structured knowledge graphs using LLMs.</li> <li>Providing Schema: Provide your own custom schema or use existing schema in settings to generate graph.</li> <li>View Graph: View graph for a particular source or multiple sources at a time in Bloom.</li> <li>Chat with Data: Interact with your data in a Neo4j database through conversational queries, also retrieve metadata about the source of response to your queries.For a dedicated chat interface, access the standalone chat application at: Chat-Only. This link provides a focused chat experience for querying your data.</li> </ul>"},{"location":"Getting%20Started/2-Config/#getting-started","title":"Getting started","text":"<p> You will need to have a Neo4j Database 5.23 or later with APOC installed to use this Knowledge Graph Builder. You can use any Neo4j Aura database (including the free database) If you are using Neo4j Desktop, you will not be able to use the docker-compose but will have to follow the separate deployment of backend and frontend section. </p>"},{"location":"Getting%20Started/2-Config/#deployment","title":"Deployment","text":""},{"location":"Getting%20Started/2-Config/#local-deployment","title":"Local deployment","text":""},{"location":"Getting%20Started/2-Config/#running-through-docker-compose","title":"Running through docker-compose","text":"<p>By default only OpenAI and Diffbot are enabled since Gemini requires extra GCP configurations. According to enviornment we are configuring the models which is indicated by VITE_LLM_MODELS_PROD variable we can configure model based on our need.</p> <p>EX: <pre><code>VITE_LLM_MODELS_PROD=\"openai_gpt_4o,openai_gpt_4o_mini,diffbot,gemini_1.5_flash\"\n</code></pre></p>"},{"location":"Getting%20Started/2-Config/#additional-configs","title":"Additional configs","text":"<p>By default, the input sources will be: Local files, Youtube, Wikipedia ,AWS S3 and Webpages. As this default config is applied: <pre><code>VITE_REACT_APP_SOURCES=\"local,youtube,wiki,s3,web\"\n</code></pre></p> <p>If however you want the Google GCS integration, add <code>gcs</code> and your Google client ID: <pre><code>VITE_REACT_APP_SOURCES=\"local,youtube,wiki,s3,gcs,web\"\nVITE_GOOGLE_CLIENT_ID=\"xxxx\"\n</code></pre></p> <p>You can of course combine all (local, youtube, wikipedia, s3 and gcs) or remove any you don't want/need.</p>"},{"location":"Getting%20Started/2-Config/#chat-modes","title":"Chat Modes","text":"<p>By default,all of the chat modes will be available: vector, graph_vector, graph, fulltext, graph_vector_fulltext , entity_vector and global_vector.</p> <p>If none of the mode is mentioned in the chat modes variable all modes will be available: <pre><code>VITE_CHAT_MODES=\"\"\n</code></pre></p> <p>If however you want to specify the only vector mode or only graph mode you can do that by specifying the mode in the env: <pre><code>VITE_CHAT_MODES=\"vector,graph\"\nVITE_CHAT_MODES=\"vector,graph\"\n</code></pre></p>"},{"location":"Getting%20Started/2-Config/#running-backend-and-frontend-separately-dev-environment","title":"Running Backend and Frontend separately (dev environment)","text":"<p>Alternatively, you can run the backend and frontend separately:</p> <ul> <li>For the frontend:</li> <li>Create the frontend/.env file by copy/pasting the frontend/example.env.</li> <li> <p>Change values as needed 3.     <pre><code>cd frontend\nyarn\nyarn run dev\n</code></pre></p> </li> <li> <p>For the backend:</p> </li> <li>Create the backend/.env file by copy/pasting the backend/example.env. To streamline the initial setup and testing of the application, you can preconfigure user credentials directly within the backend .env file. This bypasses the login dialog and allows you to immediately connect with a predefined user.</li> <li>NEO4J_URI:</li> <li>NEO4J_USERNAME:</li> <li>NEO4J_PASSWORD:</li> <li>NEO4J_DATABASE:</li> <li>Change values as needed 4.     <pre><code>cd backend\npython -m venv envName\nsource envName/bin/activate \npip install -r requirements.txt\nuvicorn score:app --reload\n</code></pre></li> </ul>"},{"location":"Getting%20Started/2-Config/#deploy-in-cloud","title":"Deploy in Cloud","text":"<p>To deploy the app and packages on Google Cloud Platform, run the following command on google cloud run: <pre><code># Frontend deploy \ngcloud run deploy dev-frontend \nsource location current directory &gt; Frontend\nregion : 32 [us-central 1]\nAllow unauthenticated request : Yes\n</code></pre> <pre><code># Backend deploy \ngcloud run deploy --set-env-vars \"OPENAI_API_KEY = \" --set-env-vars \"DIFFBOT_API_KEY = \" --set-env-vars \"NEO4J_URI = \" --set-env-vars \"NEO4J_PASSWORD = \" --set-env-vars \"NEO4J_USERNAME = \"\nsource location current directory &gt; Backend\nregion : 32 [us-central 1]\nAllow unauthenticated request : Yes\n</code></pre></p>"},{"location":"Getting%20Started/2-Config/#env","title":"ENV","text":"Env Variable Name Mandatory/Optional Default Value Description BACKEND ENV OPENAI_API_KEY Mandatory An OpenAPI Key is required to use open LLM model to authenticate andn track requests DIFFBOT_API_KEY Mandatory API key is required to use Diffbot's NLP service to extraction entities and relatioship from unstructured data BUCKET Mandatory bucket name to store uploaded file on GCS NEO4J_USER_AGENT Optional llm-graph-builder Name of the user agent to track neo4j database activity ENABLE_USER_AGENT Optional true Boolean value to enable/disable neo4j user agent DUPLICATE_TEXT_DISTANCE Mandatory 5 This value used to find distance for all node pairs in the graph and calculated based on node properties DUPLICATE_SCORE_VALUE Mandatory 0.97 Node score value to match duplicate node EFFECTIVE_SEARCH_RATIO Mandatory 1 GRAPH_CLEANUP_MODEL Optional 0.97 Model name to clean-up graph in post processing MAX_TOKEN_CHUNK_SIZE Optional 10000 Maximum token size to process file content YOUTUBE_TRANSCRIPT_PROXY Optional Proxy key to process youtube video for getting transcript EMBEDDING_MODEL Optional all-MiniLM-L6-v2 Model for generating the text embedding (all-MiniLM-L6-v2 , openai , vertexai) IS_EMBEDDING Optional true Flag to enable text embedding KNN_MIN_SCORE Optional 0.94 Minimum score for KNN algorithm GEMINI_ENABLED Optional False Flag to enable Gemini GCP_LOG_METRICS_ENABLED Optional False Flag to enable Google Cloud logs NUMBER_OF_CHUNKS_TO_COMBINE Optional 5 Number of chunks to combine when processing embeddings UPDATE_GRAPH_CHUNKS_PROCESSED Optional 20 Number of chunks processed before updating progress NEO4J_URI Optional neo4j://database:7687 URI for Neo4j database NEO4J_USERNAME Optional neo4j Username for Neo4j database NEO4J_PASSWORD Optional password Password for Neo4j database LANGCHAIN_API_KEY Optional API key for Langchain LANGCHAIN_PROJECT Optional Project for Langchain LANGCHAIN_TRACING_V2 Optional true Flag to enable Langchain tracing GCS_FILE_CACHE Optional False If set to True, will save the files to process into GCS. If set to False, will save the files locally LANGCHAIN_ENDPOINT Optional https://api.smith.langchain.com Endpoint for Langchain API ENTITY_EMBEDDING Optional False If set to True, It will add embeddings for each entity in database LLM_MODEL_CONFIG_ollama_ Optional Set ollama config as - model_name,model_local_url for local deployments RAGAS_EMBEDDING_MODEL Optional openai embedding model used by ragas evaluation framework FRONTEND ENV VITE_BACKEND_API_URL Optional http://localhost:8000 URL for backend API VITE_BLOOM_URL Optional https://workspace-preview.neo4j.io/workspace/explore?connectURL={CONNECT_URL}&amp;search=Show+me+a+graph&amp;featureGenAISuggestions=true&amp;featureGenAISuggestionsInternal=true URL for Bloom visualization VITE_REACT_APP_SOURCES Mandatory local,youtube,wiki,s3 List of input sources that will be available VITE_CHAT_MODES Mandatory vector,graph+vector,graph,hybrid Chat modes available for Q&amp;A VITE_ENV Mandatory DEV or PROD Environment variable for the app VITE_TIME_PER_PAGE Optional 50 Time per page for processing VITE_CHUNK_SIZE Optional 5242880 Size of each chunk of file for upload VITE_GOOGLE_CLIENT_ID Optional Client ID for Google authentication VITE_LLM_MODELS_PROD Optional openai_gpt_4o,openai_gpt_4o_mini,diffbot,gemini_1.5_flash To Distinguish models based on the Enviornment PROD or DEV VITE_LLM_MODELS Optional 'diffbot,openai_gpt_3.5,openai_gpt_4o,openai_gpt_4o_mini,gemini_1.5_pro,gemini_1.5_flash,azure_ai_gpt_35,azure_ai_gpt_4o,ollama_llama3,groq_llama3_70b,anthropic_claude_3_5_sonnet' Supported Models For the application VITE_AUTH0_CLIENT_ID Mandatory if you are enabling Authentication otherwise it is optional Okta Oauth Client ID for authentication VITE_AUTH0_DOMAIN Mandatory if you are enabling Authentication otherwise it is optional Okta Oauth Cliend Domain VITE_SKIP_AUTH Optional true Flag to skip the authentication VITE_CHUNK_OVERLAP Optional 20 variable to configure chunk overlap VITE_TOKENS_PER_CHUNK Optional 100 variable to configure tokens count per chunk.This gives flexibility for users who may require different chunk sizes for various tokenization tasks, especially when working with large datasets or specific language models. VITE_CHUNK_TO_COMBINE Optional 1 variable to configure number of chunks to combine for parllel processing."},{"location":"Getting%20Started/2-Config/#llms-supported","title":"LLMs Supported","text":"<ol> <li>OpenAI</li> <li>Gemini</li> <li>Diffbot</li> <li>Azure OpenAI(dev deployed version)</li> <li>Anthropic(dev deployed version)</li> <li>Fireworks(dev deployed version)</li> <li>Groq(dev deployed version)</li> <li>Amazon Bedrock(dev deployed version)</li> <li>Ollama(dev deployed version)</li> <li>Deepseek(dev deployed version)</li> <li>Other OpenAI compabtile baseurl models(dev deployed version)</li> </ol>"},{"location":"Getting%20Started/2-Config/#for-local-llms-ollama","title":"For local llms (Ollama)","text":"<ol> <li>Pull the docker imgage of ollama <pre><code>docker pull ollama/ollama\n</code></pre></li> <li>Run the ollama docker image <pre><code>docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n</code></pre></li> <li>Pull specific ollama model. <pre><code>ollama pull llama3\n</code></pre></li> <li>Execute any llm model ex\ud83e\udd993 <pre><code>docker exec -it ollama ollama run llama3\n</code></pre></li> <li>Configure  env variable in docker compose. <pre><code>LLM_MODEL_CONFIG_ollama_&lt;model_name&gt;\n#example\nLLM_MODEL_CONFIG_ollama_llama3=${LLM_MODEL_CONFIG_ollama_llama3-llama3,\nhttp://host.docker.internal:11434}\n</code></pre></li> <li>Configure the backend API url <pre><code>VITE_BACKEND_API_URL=${VITE_BACKEND_API_URL-backendurl}\n</code></pre></li> <li>Open the application in browser and select the ollama model for the extraction.</li> <li>Enjoy Graph Building.</li> </ol>"},{"location":"Getting%20Started/2-Config/#usage","title":"Usage","text":"<ol> <li>Connect to Neo4j Aura Instance which can be both AURA DS or AURA DB by passing URI and password through Backend env, fill using login dialog or drag and drop the Neo4j credentials file.</li> <li>To differntiate we have added different icons. For AURA DB we have a database icon and for AURA DS we have scientific molecule icon right under Neo4j Connection details label.</li> <li>Choose your source from a list of Unstructured sources to create graph.</li> <li>Change the LLM (if required) from drop down, which will be used to generate graph.</li> <li>Optionally, define schema(nodes and relationship labels) in entity graph extraction settings.</li> <li>Either select multiple files to 'Generate Graph' or all the files in 'New' status will be processed for graph creation.</li> <li>Have a look at the graph for individual files using 'View' in grid or select one or more files and 'Preview Graph'</li> <li>Ask questions related to the processed/completed sources to chat-bot, Also get detailed information about your answers generated by LLM.</li> </ol>"},{"location":"Getting%20Started/2-Config/#links","title":"Links","text":"<p>LLM Knowledge Graph Builder Application</p> <p>Neo4j Workspace</p>"},{"location":"Getting%20Started/2-Config/#reference","title":"Reference","text":"<p>Demo of application</p>"},{"location":"Getting%20Started/2-Config/#contact","title":"Contact","text":"<p>For any inquiries or support, feel free to raise Github Issue</p>"},{"location":"Getting%20Started/2-Config/#license","title":"\u2696\ufe0f License","text":"<p>Apache-2.0 license.  Feel free to use and extend.</p>"},{"location":"Getting%20Started/3-Deploy/Deployment/","title":"Deployment Guide","text":"","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#deployment-guide-for-ultrarepo-graph-rag","title":"Deployment Guide for UltraRepo Graph RAG","text":"<p>This guide will help you deploy the system on a VPS or on your local machine.</p> <p>Neo4j Setup Info</p> <p>You will need to have a Neo4j Database 5.23 or later with APOC installed to use this Knowledge Graph Builder.</p> <p>You can use any Neo4j Aura database (including the free database).</p> <p>If you are using Neo4j Desktop, you will not be able to use the <code>docker-compose</code> but will have to follow the separate deployment of backend and frontend section.</p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#deployment","title":"Deployment","text":"","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#local-deployment","title":"Local deployment","text":"","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#running-through-docker-compose","title":"Running through docker-compose","text":"<p>By default only OpenAI and Diffbot are enabled since Gemini requires extra GCP configurations. According to enviornment we are configuring the models which is indicated by VITE_LLM_MODELS_PROD variable we can configure model based on our need.</p> <p>EX: <pre><code>VITE_LLM_MODELS_PROD=\"openai_gpt_4o,openai_gpt_4o_mini,diffbot,gemini_1.5_flash\"\n</code></pre></p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#additional-configs","title":"Additional configs","text":"<p>By default, the input sources will be: Local files, Youtube, Wikipedia ,AWS S3 and Webpages. As this default config is applied: <pre><code>VITE_REACT_APP_SOURCES=\"local,youtube,wiki,s3,web\"\n</code></pre></p> <p>If however you want the Google GCS integration, add <code>gcs</code> and your Google client ID: <pre><code>VITE_REACT_APP_SOURCES=\"local,youtube,wiki,s3,gcs,web\"\nVITE_GOOGLE_CLIENT_ID=\"xxxx\"\n</code></pre></p> <p>You can of course combine all (local, youtube, wikipedia, s3 and gcs) or remove any you don't want/need.</p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#chat-modes","title":"Chat Modes","text":"<p>By default,all of the chat modes will be available: vector, graph_vector, graph, fulltext, graph_vector_fulltext , entity_vector and global_vector.</p> <p>If none of the mode is mentioned in the chat modes variable all modes will be available: <pre><code>VITE_CHAT_MODES=\"\"\n</code></pre></p> <p>If however you want to specify the only vector mode or only graph mode you can do that by specifying the mode in the env: <pre><code>VITE_CHAT_MODES=\"vector,graph\"\nVITE_CHAT_MODES=\"vector,graph\"\n</code></pre></p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#running-backend-and-frontend-separately-dev-environment","title":"Running Backend and Frontend separately (dev environment)","text":"<p>Alternatively, you can run the backend and frontend separately:</p> <ul> <li>For the frontend:</li> <li>Create the frontend/.env file by copy/pasting the frontend/example.env.</li> <li> <p>Change values as needed 3.     <pre><code>cd frontend\nyarn\nyarn run dev\n</code></pre></p> </li> <li> <p>For the backend:</p> </li> <li>Create the backend/.env file by copy/pasting the backend/example.env. To streamline the initial setup and testing of the application, you can preconfigure user credentials directly within the backend .env file. This bypasses the login dialog and allows you to immediately connect with a predefined user.</li> <li>NEO4J_URI:</li> <li>NEO4J_USERNAME:</li> <li>NEO4J_PASSWORD:</li> <li>NEO4J_DATABASE:</li> <li>Change values as needed 4.     <pre><code>cd backend\npython -m venv envName\nsource envName/bin/activate \npip install -r requirements.txt\nuvicorn score:app --reload\n</code></pre></li> </ul>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#deploy-in-cloud","title":"Deploy in Cloud","text":"<p>To deploy the app and packages on Google Cloud Platform, run the following command on google cloud run: <pre><code># Frontend deploy \ngcloud run deploy dev-frontend \nsource location current directory &gt; Frontend\nregion : 32 [us-central 1]\nAllow unauthenticated request : Yes\n</code></pre> <pre><code># Backend deploy \ngcloud run deploy --set-env-vars \"OPENAI_API_KEY = \" --set-env-vars \"DIFFBOT_API_KEY = \" --set-env-vars \"NEO4J_URI = \" --set-env-vars \"NEO4J_PASSWORD = \" --set-env-vars \"NEO4J_USERNAME = \"\nsource location current directory &gt; Backend\nregion : 32 [us-central 1]\nAllow unauthenticated request : Yes\n</code></pre></p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#env","title":"ENV","text":"Env Variable Name Mandatory/Optional Default Value Description BACKEND ENV OPENAI_API_KEY Mandatory An OpenAPI Key is required to use open LLM model to authenticate andn track requests DIFFBOT_API_KEY Mandatory API key is required to use Diffbot's NLP service to extraction entities and relatioship from unstructured data BUCKET Mandatory bucket name to store uploaded file on GCS NEO4J_USER_AGENT Optional llm-graph-builder Name of the user agent to track neo4j database activity ENABLE_USER_AGENT Optional true Boolean value to enable/disable neo4j user agent DUPLICATE_TEXT_DISTANCE Mandatory 5 This value used to find distance for all node pairs in the graph and calculated based on node properties DUPLICATE_SCORE_VALUE Mandatory 0.97 Node score value to match duplicate node EFFECTIVE_SEARCH_RATIO Mandatory 1 GRAPH_CLEANUP_MODEL Optional 0.97 Model name to clean-up graph in post processing MAX_TOKEN_CHUNK_SIZE Optional 10000 Maximum token size to process file content YOUTUBE_TRANSCRIPT_PROXY Optional Proxy key to process youtube video for getting transcript EMBEDDING_MODEL Optional all-MiniLM-L6-v2 Model for generating the text embedding (all-MiniLM-L6-v2 , openai , vertexai) IS_EMBEDDING Optional true Flag to enable text embedding KNN_MIN_SCORE Optional 0.94 Minimum score for KNN algorithm GEMINI_ENABLED Optional False Flag to enable Gemini GCP_LOG_METRICS_ENABLED Optional False Flag to enable Google Cloud logs NUMBER_OF_CHUNKS_TO_COMBINE Optional 5 Number of chunks to combine when processing embeddings UPDATE_GRAPH_CHUNKS_PROCESSED Optional 20 Number of chunks processed before updating progress NEO4J_URI Optional neo4j://database:7687 URI for Neo4j database NEO4J_USERNAME Optional neo4j Username for Neo4j database NEO4J_PASSWORD Optional password Password for Neo4j database LANGCHAIN_API_KEY Optional API key for Langchain LANGCHAIN_PROJECT Optional Project for Langchain LANGCHAIN_TRACING_V2 Optional true Flag to enable Langchain tracing GCS_FILE_CACHE Optional False If set to True, will save the files to process into GCS. If set to False, will save the files locally LANGCHAIN_ENDPOINT Optional https://api.smith.langchain.com Endpoint for Langchain API ENTITY_EMBEDDING Optional False If set to True, It will add embeddings for each entity in database LLM_MODEL_CONFIG_ollama_ Optional Set ollama config as - model_name,model_local_url for local deployments RAGAS_EMBEDDING_MODEL Optional openai embedding model used by ragas evaluation framework FRONTEND ENV VITE_BACKEND_API_URL Optional http://localhost:8000 URL for backend API VITE_BLOOM_URL Optional https://workspace-preview.neo4j.io/workspace/explore?connectURL={CONNECT_URL}&amp;search=Show+me+a+graph&amp;featureGenAISuggestions=true&amp;featureGenAISuggestionsInternal=true URL for Bloom visualization VITE_REACT_APP_SOURCES Mandatory local,youtube,wiki,s3 List of input sources that will be available VITE_CHAT_MODES Mandatory vector,graph+vector,graph,hybrid Chat modes available for Q&amp;A VITE_ENV Mandatory DEV or PROD Environment variable for the app VITE_TIME_PER_PAGE Optional 50 Time per page for processing VITE_CHUNK_SIZE Optional 5242880 Size of each chunk of file for upload VITE_GOOGLE_CLIENT_ID Optional Client ID for Google authentication VITE_LLM_MODELS_PROD Optional openai_gpt_4o,openai_gpt_4o_mini,diffbot,gemini_1.5_flash To Distinguish models based on the Enviornment PROD or DEV VITE_LLM_MODELS Optional 'diffbot,openai_gpt_3.5,openai_gpt_4o,openai_gpt_4o_mini,gemini_1.5_pro,gemini_1.5_flash,azure_ai_gpt_35,azure_ai_gpt_4o,ollama_llama3,groq_llama3_70b,anthropic_claude_3_5_sonnet' Supported Models For the application VITE_AUTH0_CLIENT_ID Mandatory if you are enabling Authentication otherwise it is optional Okta Oauth Client ID for authentication VITE_AUTH0_DOMAIN Mandatory if you are enabling Authentication otherwise it is optional Okta Oauth Cliend Domain VITE_SKIP_AUTH Optional true Flag to skip the authentication VITE_CHUNK_OVERLAP Optional 20 variable to configure chunk overlap VITE_TOKENS_PER_CHUNK Optional 100 variable to configure tokens count per chunk.This gives flexibility for users who may require different chunk sizes for various tokenization tasks, especially when working with large datasets or specific language models. VITE_CHUNK_TO_COMBINE Optional 1 variable to configure number of chunks to combine for parllel processing.","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#llms-supported","title":"LLMs Supported","text":"<ol> <li>OpenAI</li> <li>Gemini</li> <li>Diffbot</li> <li>Azure OpenAI(dev deployed version)</li> <li>Anthropic(dev deployed version)</li> <li>Fireworks(dev deployed version)</li> <li>Groq(dev deployed version)</li> <li>Amazon Bedrock(dev deployed version)</li> <li>Ollama(dev deployed version)</li> <li>Deepseek(dev deployed version)</li> <li>Other OpenAI compabtile baseurl models(dev deployed version)</li> </ol>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#for-local-llms-ollama","title":"For local llms (Ollama)","text":"<ol> <li>Pull the docker imgage of ollama <pre><code>docker pull ollama/ollama\n</code></pre></li> <li>Run the ollama docker image <pre><code>docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n</code></pre></li> <li>Pull specific ollama model. <pre><code>ollama pull llama3\n</code></pre></li> <li>Execute any llm model ex\ud83e\udd993 <pre><code>docker exec -it ollama ollama run llama3\n</code></pre></li> <li>Configure  env variable in docker compose. <pre><code>LLM_MODEL_CONFIG_ollama_&lt;model_name&gt;\n#example\nLLM_MODEL_CONFIG_ollama_llama3=${LLM_MODEL_CONFIG_ollama_llama3-llama3,\nhttp://host.docker.internal:11434}\n</code></pre></li> <li>Configure the backend API url <pre><code>VITE_BACKEND_API_URL=${VITE_BACKEND_API_URL-backendurl}\n</code></pre></li> <li>Open the application in browser and select the ollama model for the extraction.</li> <li>Enjoy Graph Building.</li> </ol>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#usage","title":"Usage","text":"<ol> <li>Connect to Neo4j Aura Instance which can be both AURA DS or AURA DB by passing URI and password through Backend env, fill using login dialog or drag and drop the Neo4j credentials file.</li> <li>To differntiate we have added different icons. For AURA DB we have a database icon and for AURA DS we have scientific molecule icon right under Neo4j Connection details label.</li> <li>Choose your source from a list of Unstructured sources to create graph.</li> <li>Change the LLM (if required) from drop down, which will be used to generate graph.</li> <li>Optionally, define schema(nodes and relationship labels) in entity graph extraction settings.</li> <li>Either select multiple files to 'Generate Graph' or all the files in 'New' status will be processed for graph creation.</li> <li>Have a look at the graph for individual files using 'View' in grid or select one or more files and 'Preview Graph'</li> <li>Ask questions related to the processed/completed sources to chat-bot, Also get detailed information about your answers generated by LLM.</li> </ol>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#links","title":"Links","text":"<p>LLM Knowledge Graph Builder Application</p> <p>Neo4j Workspace</p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#reference","title":"Reference","text":"<p>Demo of application</p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#contact","title":"Contact","text":"<p>For any inquiries or support, feel free to raise Github Issue</p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"Getting%20Started/3-Deploy/Deployment/#license","title":"\u2696\ufe0f License","text":"<p>Apache-2.0 license.  Feel free to use and extend.</p>","tags":["deployment","mkdocs","github pages","docs"]},{"location":"backend/backend_docs/","title":"LLM Knowledge Graph Builder Backend","text":""},{"location":"backend/backend_docs/#api-reference","title":"API Reference","text":""},{"location":"backend/backend_docs/#connect-to-neo4j-graph-database","title":"Connect to Neo4j Graph Database","text":"<p>POST <code>/connect</code></p> <p>Neo4j database connection on frontend is done with this API.</p> <p>API Parameters:</p> <ul> <li><code>uri</code> - Neo4j uri</li> <li><code>userName</code> - Neo4j db username</li> <li><code>password</code> - Neo4j db password</li> <li><code>database</code> - Neo4j database name</li> </ul> <p>Response: <pre><code>{\n    \"status\": \"Success\",\n    \"data\": {\n        \"db_vector_dimension\": 384,\n        \"application_dimension\": 384,\n        \"message\": \"Connection Successful\",\n        \"gds_status\": true,\n        \"write_access\": true,\n        \"elapsed_api_time\": \"5.48\"\n    }\n}\n</code></pre></p>"},{"location":"backend/backend_docs/#upload-files-from-local","title":"Upload Files from Local","text":"<p>POST <code>/upload</code></p> <p>The upload endpoint is designed to handle the uploading of large files by breaking them into smaller chunks. This method ensures that large files can be uploaded efficiently without overloading the server.</p> <p>API Parameters:</p> <ul> <li><code>file</code> - The file to be uploaded, received in chunks</li> <li><code>chunkNumber</code> - The current chunk number being uploaded</li> <li><code>totalChunks</code> - The total number of chunks the file is divided into (each chunk of 1Mb size)</li> <li><code>originalname</code> - The original name of the file</li> <li><code>model</code> - The model associated with the file</li> <li><code>uri</code> - Neo4j uri</li> <li><code>userName</code> - Neo4j db username</li> <li><code>password</code> - Neo4j db password</li> <li><code>database</code> - Neo4j database name</li> </ul> <p>Response: <pre><code>{\n    \"status\": \"Success\",\n    \"message\": \"File uploaded and chunks merged successfully.\"\n}\n</code></pre></p>"},{"location":"backend/backend_docs/#user-defined-schema","title":"User defined schema","text":"<p>POST <code>/schema</code></p> <p>User can set schema for graph generation (i.e. Nodes and relationship labels) in settings panel or get existing db schema through this API.</p> <p>API Parameters:</p> <ul> <li><code>uri</code> - Neo4j uri</li> <li><code>userName</code> - Neo4j db username</li> <li><code>password</code> - Neo4j db password</li> <li><code>database</code> - Neo4j database name</li> </ul> <p>Response: <pre><code>{\n    \"status\": \"Success\",\n    \"data\": [\n        {\n            \"labels\": [\n                \"Access_token\",\n                \"Activity\",\n                \"Ai chatbot\",\n                \"Book\",\n                \"Metric\",\n                \"Mode\",\n                \"Mountain\"\n            ],\n            \"relationshipTypes\": [\n                \"ACCELERATE\",\n                \"ACCEPTS\",\n                \"CONVERT\",\n                \"CORRELATE\",\n                \"ESTABLISHED\",\n                \"EXAMPLE_OF\"\n            ]\n        }\n    ]\n}\n</code></pre></p>"},{"location":"backend/backend_docs/#graph-schema-from-input-text","title":"Graph schema from input text","text":"<p>POST <code>/populate_graph_schema</code></p> <p>The API is used to populate a graph schema based on the provided input text, model, and schema description flag.</p> <p>API Parameters:</p> <ul> <li><code>input_text</code> - The input text used to populate the graph schema</li> <li><code>model</code> - The model to be used for populating the graph schema</li> <li><code>is_schema_description_checked</code> - A flag indicating whether the schema description should be considered</li> </ul> <p>Response: <pre><code>{\n    \"status\": \"Success\",\n    \"data\": [\n        {\n            \"labels\": [\n                \"Technology\",\n                \"Company\",\n                \"Person\",\n                \"Location\",\n                \"Organization\",\n                \"Concept\"\n            ],\n            \"relationshipTypes\": [\n                \"LOCATED_AT\",\n                \"SUBSIDARY_OF\",\n                \"BORN_IN\",\n                \"LAST_MESSAGE\",\n                \"ATTENDED\",\n                \"PARTNERED_WITH\"\n            ]\n        }\n    ]\n}\n</code></pre></p>"},{"location":"backend/backend_docs/#unstructured-sources-scan-other-than-local","title":"Unstructured sources scan other than local","text":"<p>POST <code>/url/scan</code></p> <p>Create Document node for other sources - s3 bucket, gcs bucket, wikipedia, youtube url and web pages.</p> <p>API Parameters:</p> <ul> <li><code>uri</code> - Neo4j uri</li> <li><code>userName</code> - Neo4j db username</li> <li><code>password</code> - Neo4j db password</li> <li><code>database</code> - Neo4j database name</li> <li><code>model</code> - LLM model</li> <li><code>source_url</code> - s3 bucket url or youtube url</li> <li><code>aws_access_key_id</code> - AWS access key</li> <li><code>aws_secret_access_key</code> - AWS secret key</li> <li><code>wiki_query</code> - Wikipedia query sources</li> <li><code>gcs_project_id</code> - GCS project id</li> <li><code>gcs_bucket_name</code> - GCS bucket name</li> <li><code>gcs_bucket_folder</code> - GCS bucket folder</li> <li><code>source_type</code> - s3 bucket/ gcs bucket/ youtube/Wikipedia as source type</li> <li><code>access_token</code> - Access token for authentication</li> </ul> <p>Response: <pre><code>{\n    \"status\": \"Success\",\n    \"success_count\": 2,\n    \"failed_count\": 0,\n    \"message\": \"Source Node created successfully for source type: Wikipedia and source: Albert Einstein,  neo4j\",\n    \"file_name\": [\n        {\n            \"fileName\": \"Albert Einstein\",\n            \"fileSize\": 8074,\n            \"url\": \"https://en.wikipedia.org/wiki/Albert_Einstein\",\n            \"status\": \"Success\"\n        }\n    ]\n}\n</code></pre></p>"},{"location":"backend/backend_docs/#extraction-of-nodes-and-relations-from-content","title":"Extraction of nodes and relations from content","text":"<p>POST <code>/extract</code></p> <p>This API is responsible for:</p> <ul> <li> <p>Reading the content of source provided in the form of langchain Document object from respective langchain loaders</p> </li> <li> <p>Dividing the document into multiple chunks, and make below relations:</p> </li> <li><code>PART_OF</code> - relation from Document node to all chunk nodes</li> <li><code>FIRST_CHUNK</code> - relation from document node to first chunk node</li> <li><code>NEXT_CHUNK</code> - relation from a chunk pointing to next chunk of the document</li> <li> <p><code>HAS_ENTITY</code> - relation between chunk node and entities extracted from LLM</p> </li> <li> <p>Extracting nodes and relations in the form of GraphDocument from respective LLM</p> </li> <li> <p>Update embedding of chunks and create vector index</p> </li> <li> <p>Update K-Nearest Neighbors graph for similar chunks</p> </li> </ul> <p>Implementation:</p> <p>For multiple sources of content:</p> <ul> <li> <p>Local file - User can upload pdf file from their device</p> </li> <li> <p>s3 bucket - User passes the bucket url and all the pdf files inside folders and subfolders will be listed</p> </li> <li> <p>GCS bucket - User passes gcs project id, gcs bucket name and folder name, do google authentication to access all the pdf files under that folder and its subfolders and if folder name is not passed by user, all the pdf files under the bucket and its subfolders will be listed if user have read access of the bucket</p> </li> <li> <p>Web Sources:</p> </li> <li>Wikipedia - Wikipedia 1<sup>st</sup> page content is rendered url passed by user</li> <li>Youtube - Youtube video transcript is processed and if no transcript is available then respective error is thrown</li> <li> <p>Web urls - Text Content from any web url is processed for generating graph</p> </li> <li> <p>Langchain's LLMGraphTransformer library is used to get nodes and relations in the form of GraphDocument from LLMs. User and System prompts, LLM chain, graphDocument schema are defined in the library itself</p> </li> <li> <p>SentenceTransformer embeddings are used by default, also embeddings are made configurable to use either OpenAIEmbeddings or VertexAIEmbeddings</p> </li> <li> <p>Vector index is created in database on embeddings created for chunks</p> </li> </ul> <p>API Parameters:</p> <ul> <li><code>uri</code> - Neo4j uri</li> <li><code>userName</code> - Neo4j db username</li> <li><code>password</code> - Neo4j db password</li> <li><code>database</code> - Neo4j database name</li> <li><code>model</code> - LLM model</li> <li><code>file_name</code> = File uploaded from device</li> <li><code>source_url</code>=  , <li><code>aws_access_key_id</code>= AWS access key,</li> <li><code>aws_secret_access_key</code>= AWS secret key,</li> <li><code>wiki_query</code>= Wikipedia query sources,</li> <li><code>gcs_project_id</code>=GCS project id,</li> <li><code>gcs_bucket_name</code>= GCS bucket name,</li> <li><code>gcs_bucket_folder</code>= GCS bucket folder,</li> <li><code>gcs_blob_filename</code> = GCS file name,</li> <li><code>source_type</code>= local file/ s3 bucket/ gcs bucket/ youtube/ Wikipedia as source, allowedNodes=Node labels passed from settings panel,</li> <li><code>allowedRelationship</code>=Relationship labels passed from settings panel,</li> <li><code>language</code>=Language in which wikipedia content will be extracted</li> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"fileName\": ,         \"nodeCount\": ,         \"relationshipCount\": ,         \"processingTime\": ,         \"status\": \"Completed\",         \"model\":      } } ...."},{"location":"backend/backend_docs/#get-list-of-sources","title":"Get list of sources","text":"<p>GET <code>/sources_list</code></p> <p>List all sources (Document nodes) present in Neo4j graph database.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": [         {             \"fileName\": \"About Amazon.pdf\",             \"fileSize\": 163931,             \"errorMessage\": \"\",             \"fileSource\": \"local file\",             \"nodeCount\": 62,             \"model\": \"OpenAI GPT 4\",             \"fileType\": \"pdf\",             \"processingTime\": 122.71,             \"relationshipCount\": 187,             \"status\": \"Completed\",             \"updatedAt\": {                 \"_DateTime__date\": {                     \"_Date__ordinal\": 738993,                     \"_Date__year\": 2024,                     \"_Date__month\": 4,                     \"_Date__day\": 17                 },                 \"_DateTime__time\": {                     \"_Time__ticks\": 28640715768000,                     \"_Time__hour\": 7,                     \"_Time__minute\": 57,                     \"_Time__second\": 20,                     \"_Time__nanosecond\": 715768000,                     \"_Time__tzinfo\": null                 }             }         }     ] } ....</p>"},{"location":"backend/backend_docs/#post-processing-after-graph-generation","title":"Post processing after graph generation","text":"<p>POST <code>/post_processing</code></p> <p>This API is called at the end of processing of whole document to get create k-nearest neighbor relations between similar chunks of document based on KNN_MIN_SCORE which is 0.8 by default and to drop and create a full text index on db labels.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name</li> <li><code>tasks</code>= List of tasks to perform</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\":\"Success\",     \"message\":\"All tasks completed successfully\" } ....</p>"},{"location":"backend/backend_docs/#chat-with-data","title":"Chat with Data","text":"<p>POST <code>/chat_bot</code></p> <p>The API responsible for a chatbot system designed to leverage multiple AI models and a Neo4j graph database, providing answers to user queries. It interacts with AI models from OpenAI and Google's Vertex AI and utilizes embedding models to enhance the retrieval of relevant information.</p> <p>Components: </p> <p>** Embedding Models - Includes OpenAI Embeddings, VertexAI Embeddings, and SentenceTransformer Embeddings(Default) to support vector-based query operations. ** AI Models - OpenAI GPT 3.5, GPT 4o, GPT 40 mini, gemini_1.5_flash can be configured for the chatbot backend to generate responses and process natural language. ** Graph Database (Neo4jGraph) - Manages interactions with the Neo4j database, retrieving, and storing conversation histories. ** Response Generation - Utilizes Vector Embeddings from the Neo4j database, chat history, and the knowledge base of the LLM used. ** Chat Modes - Vector , Graph, Vector + Graph, Fulltext, Vector + Graph+Fulltext, Entity Search + Vector, Global search Vector </p> <p>API Parameters:</p> <ul> <li><code>uri</code>= Neo4j uri</li> <li><code>userName</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>model</code>= LLM model</li> <li><code>question</code>= User query for the chatbot</li> <li><code>session_id</code>= Session ID used to maintain the history of chats during the user's connection </li> <li><code>mode</code> = chat mode to use </li> <li><code>document_names</code> = the names of documents to be filtered works for vector mode and vector+Graph mode </li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"session_id\": \"0cbd04a8-abc3-4776-b393-6a9a2cea36b3\",         \"message\": \"response generated by the chat\",         \"info\": {             \"sources\": [                 \"About Amazon.pdf\"             ],             \"model\": \"gpt-4o-2024-08-06\",             \"nodedetails\": {                 \"chunkdetails\": [                     {                         \"id\": \"73bc9c9170bcd807d2fa87d87a0eeb3d82f95160\",                         \"score\": 1.0                     },                     {                         \"id\": \"de5486776978353c9f8ac530bcff33eeecbdbbad\",                         \"score\": 0.9425                     }                 ],                 \"entitydetails\": [],                 \"communitydetails\": []             },             \"total_tokens\": 4575,             \"response_time\": 17.19,             \"mode\": \"graph_vector_fulltext\",             \"entities\": {                 \"entityids\": [                     \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:307\",                     \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:1877\",                 ],                 \"relationshipids\": [                     \"5:98e5e9bb-8095-440d-9462-03985fed2fa2:8072566611095062357\",                     \"5:98e5e9bb-8095-440d-9462-03985fed2fa2:8072566508015847224\"                 ]             },             \"metric_details\": {                 \"question\": \"tell me about amazon \",                 \"contexts\": \"context sent to LLM\"                 \"answer\": \"response generated by the LLM\"             }         },         \"user\": \"chatbot\"     } } ....</p>"},{"location":"backend/backend_docs/#get-entities-from-chunks","title":"Get entities from chunks","text":"<p>/chunk_entities</p> <p>This API is used to  get the entities and relations associated with a particular chunk and chunk metadata.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name</li> <li><code>nodedetails</code> = Node element id's to get information(chunks,entities,communities)</li> <li><code>entities</code> = entities received from the retriver for graph based modes</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"nodes\": [             {                 \"element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:307\",                 \"labels\": [                     \"Company\"                 ],                 \"properties\": {                     \"id\": \"Amazon\",                     \"description\": \"Initially an online bookstore, Amazon has transformed into a $48 billion retail giant, offering products in over forty categories, from books and electronics to groceries. Today, it operates as a logistics platform, a search engine, an Internet advertising platform, an e-commerce platform, and an IT platform.\"                 }             }         ],         \"relationships\": [             {                 \"element_id\": \"5:98e5e9bb-8095-440d-9462-03985fed2fa2:6917952339617775946\",                 \"type\": \"OFFERS\",                 \"start_node_element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:307\",                 \"end_node_element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:330\"             }         ],         \"chunk_data\": [             {                 \"element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:14\",                 \"id\": \"d1e92be81a0872d621242cee9fed69d14b0cd68d\",                 \"position\": 13,                 \"text\": \" 6 eBay, operating as the biggest online auction house and focusing as a service provider, employs cost leadership strategy by solely operating e-commerce as an intermediary without holding any inventories or physical infrastructures. It also applies a differentiation strategy by providing a ....\",                 \"content_offset\": 9886,                 \"fileName\": \"About Amazon.pdf\",                 \"page_number\": 7,                 \"length\": 1024,                 \"fileSource\": \"local file\",                 \"embedding\": null             }         ],         \"community_data\": [             {                 \"element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:1026\",                 \"summary\": \"Google, led by CEO Sundar Pichai, is actively involved in various business and product initiatives.\",                 \"id\": \"0-311\",                 \"level\": 0,                 \"weight\": 7,                 \"embedding\": null,                 \"community_rank\": 1             }         ]     },     \"message\": \"Total elapsed API time 3.75\" } ....</p>"},{"location":"backend/backend_docs/#view-graph-for-a-file","title":"View graph for a file","text":"<p>POST <code>/graph_query</code></p> <p>This API is used to view graph for a particular file.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>query_type</code>= Neo4j database name</li> <li><code>document_names</code> = File name for which user wants to view graph</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"nodes\": [             {                 \"element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:9972\",                 \"labels\": [                     \"Person\"                 ],                 \"properties\": {                     \"id\": \"Jeff\"                 }             },             {                 \"element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:9973\",                 \"labels\": [                     \"Team\"                 ],                 \"properties\": {                     \"id\": \"Miami\"                 }             }         ],         \"relationships\": [             {                 \"element_id\": \"5:98e5e9bb-8095-440d-9462-03985fed2fa2:1153200780560312052\",                 \"type\": \"PLAYER\",                 \"start_node_element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:9972\",                 \"end_node_element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:9973\"             }         ]     } }   ....</p>"},{"location":"backend/backend_docs/#get-neighbour-nodes","title":"Get neighbour nodes","text":"<p>POST <code>/get_neighbours</code></p> <p>This API is used to retrive the neighbor nodes of the given element id of the node.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> <li><code>elementId</code> = Element id of the node to retrive its neighbours</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"nodes\": [             {                 \"summary\": null,                 \"element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:3\",                 \"id\": \"73bc9c9170bcd807d2fa87d87a0eeb3d82f95160\",                 \"position\": 2,                 \"text\": null,                 \"content_offset\": 186,                 \"labels\": [                     \"Chunk\"                 ],                 \"page_number\": 2,                 \"fileName\": \"About Amazon.pdf\",                 \"length\": 904,                 \"properties\": {                     \"id\": \"73bc9c9170bcd807d2fa87d87a0eeb3d82f95160\"                 },                 \"embedding\": null             }         ],         \"relationships\": [             {                 \"element_id\": \"5:98e5e9bb-8095-440d-9462-03985fed2fa2:1175445000301838339\",                 \"end_node_element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:18\",                 \"start_node_element_id\": \"4:98e5e9bb-8095-440d-9462-03985fed2fa2:3\",                 \"type\": \"HAS_ENTITY\"             },         ]     },     \"message\": \"Total elapsed API time 0.24\" } ....</p>"},{"location":"backend/backend_docs/#clear-chat-history","title":"Clear chat history","text":"<p>POST <code>/clear_chat_bot</code></p> <p>This API is used to clear the chat history which is saved in Neo4j DB.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> <li><code>session_id</code> = User session id for QA chat</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"session_id\": \"99c1a808-377f-448f-9ea6-4b4a8de46b14\",         \"message\": \"The chat History is cleared\",         \"user\": \"chatbot\"     } } ....</p>"},{"location":"backend/backend_docs/#sse-event-to-update-processing-status","title":"SSE event to update processing status","text":"<p>GET <code>/update_extract_status</code></p> <p>The API provides a continuous update on the extraction status of a specified file. It uses Server-Sent Events (SSE) to stream updates to the client.</p> <p>API Parameters:</p> <ul> <li><code>file_name</code>=The name of the file whose extraction status is being tracked,</li> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name</li> </ul> <p>Response: [source,json,indent=0] .... {     \"fileName\": \"testFile.pdf\",      \"status\": \"Processing\",      \"processingTime\": 0,      \"nodeCount\": 0,      \"relationshipCount\": 0,      \"model\": \"OpenAI GPT 3.5\",      \"total_chunks\": 3,      \"fileSize\": 92373,      \"processed_chunk\": 0 } ....</p>"},{"location":"backend/backend_docs/#delete-selected-documents","title":"Delete selected documents","text":"<p>POST <code>/delete_document_and_entities</code></p> <p>Overview:</p> <p>Deleteion of nodes and relations for multiple files is done through this API. User can choose multiple documents to be deleted, also user have option to delete only 'Document' and 'Chunk' nodes and keep the entities extracted from that document. </p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> <li><code>filenames</code>= List of files to be deleted,</li> <li><code>source_types</code>= Document sources(Wikipedia, youtube, etc.),</li> <li><code>deleteEntities</code>= Boolean value to check entities deletion is requested or not</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"message\": \"Deleted 1 documents with 68 entities from database\" } ....</p>"},{"location":"backend/backend_docs/#cancel-processing-job","title":"Cancel processing job","text":"<p>/cancelled_job</p> <p>This API is responsible for cancelling an in process job.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> <li><code>filenames</code>= Name of the file whose processing need to be stopped, </li> <li><code>source_types</code>= Source of the file</li> </ul> <p>Response: [source,json,indent=0] .... {     \"message\":\"Cancelled the processing job successfully\" } ....</p>"},{"location":"backend/backend_docs/#get-the-list-of-orphan-nodes","title":"Get the list of orphan nodes","text":"<p>POST <code>/get_unconnected_nodes_list</code></p> <p>The API retrieves a list of nodes in the graph database that are not connected to any other nodes.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name</li> </ul> <p>Response: [source,json,indent=0] .... {   \"status\": \"Success\",     \"data\": [       \"e\":          {                   \"id\": \"Leela Chess Zero\",                   \"elementId\": \"4:abf6f691-928d-4b1c-80fc-2914ae517b4c:336\",                   \"labels\": [\"Technology\"],                   \"embedding\": null              },             \"documents\": [\"AlphaZero - Wikipedia.pdf\"],       \"chunkConnections\": 7     ] } ....</p>"},{"location":"backend/backend_docs/#deletion-of-orpahn-nodes","title":"Deletion of orpahn nodes","text":"<p>POST <code>/delete_unconnected_nodes</code></p> <p>The API is used to delete unconnected entities from database.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> <li><code>unconnected_entities_list</code>=selected entities list to delete of unconnected entities.</li> </ul> <p>Response: [source,json,indent=0] .... {      \"status\": \"Success\",     \"message: \"Unconnected entities delete successfully\" } ....</p>"},{"location":"backend/backend_docs/#decisions","title":"Decisions","text":"<ul> <li>Process only 1<sup>st</sup> page of Wikipedia</li> <li>Split document content into chunks of size 200 and overlap of 20</li> <li>Configurable elements - ** Number of chunks to combine ** Generate Embedding or not  ** Embedding model ** minimum score for KNN graph ** Uploaded file storage location (GCS bucket or container)</li> </ul>"},{"location":"backend/backend_docs/#get-duplicate-nodes","title":"Get duplicate nodes","text":"<p>POST <code>/get_duplicate_nodes</code></p> <p>The API is used to fetch duplicate entities from database.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": [         {             \"e\": {                 \"id\": \"13 September 2024\",                 \"elementId\": \"4:b104b2e7-e2ed-4902-b78b-7ad1518ca04f:14007\",                 \"communities\": [                     2969,                     383,                     81                 ],                 \"labels\": [                     \"Entity\",                     \"Date\"                 ],                 \"embedding\": null             },             \"similar\": [                 {                     \"id\": \"20 September 2024\",                     \"elementId\": \"4:b104b2e7-e2ed-4902-b78b-7ad1518ca04f:14153\",                     \"description\": null,                     \"labels\": [                         \"Entity\",                         \"Date\"                     ]                 }             ],             \"documents\": [],             \"chunkConnections\": 0         }     ],     \"message\": {         \"total\": 1     } } ....</p>"},{"location":"backend/backend_docs/#merge-duplicate-nodes","title":"Merge duplicate nodes","text":"<p>POST <code>/merge_duplicate_nodes</code></p> <p>The API is used to merge duplicate entities from database selected by user.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> <li><code>duplicate_nodes_list</code>= selected entities list to merge of with similar entities.</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": [         {             \"totalMerged\": 2         }     ],     \"message\": \"Duplicate entities merged successfully\" } ....</p>"},{"location":"backend/backend_docs/#drop-and-create-vector-index","title":"Drop and create vector index","text":"<p>POST <code>/drop_create_vector_index</code></p> <p>The API is used to drop and create the vector index when vector index dimesion are different.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name,</li> <li><code>isVectorIndexExist</code>= True or False based on whether vector index exist in database,</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"message\": \"Drop and Re-Create vector index succesfully\" } ....</p>"},{"location":"backend/backend_docs/#reprocessing-of-sources","title":"Reprocessing of sources","text":"<p>POST <code>/retry_processing</code></p> <p>This API is used to Ready to Reprocess cancelled, completed or failed file sources. Users have 3 options to Ready to Reprocess files:</p> <ul> <li>Start from begnning - In this condition file will be processed from the begnning i.e. 1<sup>st</sup> chunk again.</li> <li>Delete entities and start from begnning - If the file source is already processed and have any existing nodes and relations then those will be deleted and file will be reprocessed from the 1<sup>st</sup> chunk.</li> <li>Start from last processed postion - Cancelled or failed files will be processed from the last successfully processed chunk position. This option is not available for completed files.</li> </ul> <p>Ones the status is set to 'Ready to Reprocess', user can again click on Generate graph to process the file for knowledge graph creation.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri,</li> <li><code>userName</code>= Neo4j db username,</li> <li><code>password</code>= Neo4j db password,</li> <li><code>database</code>= Neo4j database name,</li> <li><code>file_name</code>= Name of the file which user want to Ready to Reprocess.</li> <li><code>retry_condition</code> = One of the above 3 conditions which is selected for reprocessing.</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"message\": \"Status set to Ready to Reprocess for filename : $filename\" } ....</p>"},{"location":"backend/backend_docs/#evaluate-response","title":"Evaluate response","text":"<p>POST <code>/metric</code></p> <p>The API responsible for a evaluating chatbot responses on the basis of different metrics such as faithfulness and answer relevancy. This utilises RAGAS library to calculate these metrics.</p> <p>API Parameters:</p> <ul> <li><code>question</code>= User query for the chatbot</li> <li><code>context</code>= context retrieved by retrieval mode used for answer generation</li> <li><code>answer</code>= answer generated by chatbot</li> <li><code>model</code>= LLM model</li> <li><code>mode</code>= Retrieval mode used for answer generationRetrieval mode used for answer generation</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"graph+vector+fulltext\": {             \"faithfulness\": 1.0,             \"answer_relevancy\": 0.9699         }     } } ....</p>"},{"location":"backend/backend_docs/#evaluate-response-with-ground-truth","title":"Evaluate response with ground truth","text":"<p>POST <code>/additional_metrics</code></p> <p>The API responsible for a evaluating chatbot responses on the basis of different metrics such as context entity recall, semantic score, rouge score. This reuqire additional ground truth to be supplied by user. This utilises RAGAS library to calculate these metrics.</p> <p>API Parameters:</p> <ul> <li><code>question</code>= User query for the chatbot</li> <li><code>context</code>= context retrieved by retrieval mode used for answer generation</li> <li><code>answer</code>= answer generated by chatbot</li> <li><code>reference</code>= ground truth/ expected answer provided by user</li> <li><code>model</code>= LLM model</li> <li><code>mode</code>= Retrieval mode used for answer generationRetrieval mode used for answer generation</li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"graph_vector_fulltext\": {             \"rouge_score\": 1.0,             \"semantic_score\": 0.9842,             \"context_entity_recall_score\": 0.5         }     } } ....</p>"},{"location":"backend/backend_docs/#fetch-chunk-text","title":"Fetch chunk text","text":"<p>POST <code>/fetch_chunktext</code></p> <p>The API responsible for a fetching text associated with a particular chunk and chunk metadata.</p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name</li> <li><code>document_name</code> = Name of document for which chunks needs to be fetched.</li> <li><code>page no</code> = page number for multipage  </li> </ul> <p>Response: [source,json,indent=0] .... {     \"status\": \"Success\",     \"data\": {         \"pageitems\": [             {                 \"text\": \"By T. Albert  Illustrated by: maaillustrations.com  Science has never been so much fun. Here is all that a child needs to know about water, rain, hail, sleet and water cycle. When Professor Mois Ture teaches- little readers read, learn and ask for more\u2026..  Published by Monkey Pen Ltd  Dear Supporter,  Thank you for downloading our childrens books. Monkey Pens Vision is to provide thousands of free childrens books to young readers around the globe.  Please share our books with your friends and family to support our mission. Thank you  Please make a donation on Patreon to support Monkey Pens Free Book Project:  Hi, I am Professor Mois Ture and I will be telling you about water. You can call it RAIN. You can call it SNOW. You can call it SLEET. You can call it HAIL. But it's WATER all the same. Did you ever wonder how\",                 \"position\": 1,                 \"pagenumber\": 1             },             {                 \"text\": \" it HAIL. But it's WATER all the same. Did you ever wonder how old water is or where it comes from? The answers may surprise you.  The next time you see a pond or even a glass of water, think about how old that water might be. Do you really want to know ? I thought you did.  Did you brush your teeth this morning? Well, some of the water that you used could have fallen from the sky yesterday, or a week, or month ago. It's pretty new.  But, some part of that water is very old and was around during the time of the dinosaurs, or even longer. Or maybe it's a little newer; like from the time when the Pharaohs were building pyramids.  You see there is only a limited amount of water and it gets recycled. Yep! It keeps going round and round. We call it the \"Water Cycle.\"  Yes \u2013 You\",                 \"position\": 2,                 \"pagenumber\": 2             }         ],         \"total_pages\": 1     },     \"message\": \"Total elapsed API time 0.48\" }</p> <p>....</p>"},{"location":"backend/backend_docs/#backend-database-connection","title":"Backend Database connection","text":"<p>POST <code>/backend_connection_configuation</code></p> <p>The API responsible for create the connection obj from Neo4j DB based on environment variable and return the status for show/hide login dialog on UI </p> <p>Response: [source,json,indent=0] .... {   \"status\": \"Success\",   \"data\": true,   \"message\": \"Backend connection successful\" } ....</p> <p>.... {   \"status\": \"Failed\",   \"error\": \"Could not connect to Neo4j database. Please ensure that the username and password are correct\",   \"message\": \"Unable to connect backend DB\" } ....</p>"},{"location":"backend/backend_docs/#visualize-graph-db-schema","title":"Visualize graph DB schema","text":"<p>POST <code>/schema_visualization</code></p> <p>User can visualize schema of the db through this API. </p> <p>API Parameters:</p> <ul> <li><code>uri</code>=Neo4j uri, </li> <li><code>userName</code>= Neo4j db username, </li> <li><code>password</code>= Neo4j db password, </li> <li><code>database</code>= Neo4j database name</li> </ul> <p>Response: [source,json,indent=0] .... {   \"status\": \"Success\",   \"data\": {     \"nodes\": [       {         \"element_id\": \"-5374\",         \"labels\": [           \"Entity\"         ],         \"properties\": {           \"name\": \"Entity\",           \"indexes\": [             \"id,description\"           ],           \"constraints\": []         }       },     ],     \"relationships\": [       {         \"element_id\": \"-44223\",         \"end_node_element_id\": \"-5411\",         \"start_node_element_id\": \"-5342\",         \"properties\": {           \"name\": \"OWNED\"         },         \"type\": \"OWNED\"       },      ]   },   \"message\": \"Total elapsed API time 3.51\" } ....</p>"},{"location":"frontend/frontend_docs/","title":"LLM Knowledge Graph Builder Frontend","text":""},{"location":"frontend/frontend_docs/#objective","title":"Objective","text":"<p>This document provides a comprehensive guide for developers on how we build a React application integrated with Neo4j Aura for graph database functionalities. The application allows users to connect to a Neo4j Aura instance and we show you how to automatically create a graph from the unstructured text. We allow users to upload documents locally and from cloud buckets, YouTube videos, and Wikipedia pages, configure a graph schema, extract the lexical, entity and knowledge graph, visualize the extracted graph, ask questions and see the details that were used to generate the answers.</p>"},{"location":"frontend/frontend_docs/#architecture-structure","title":"Architecture Structure","text":"<ul> <li>For Knowledge Graph builder App:</li> <li>React JS \u2013 Application logic</li> <li>Axios \u2013 for network calls and handling responses</li> <li>Styled Components \u2013 To handle CSS in JS \u2013 Where we write all CSS ourselves, Or Tailwind CSS \u2013 3<sup>rd</sup> party CSS classes to speed up development</li> <li>LongPooling: Long polling can be conceptualized as the simplest way to maintain a steady connection between a client and a server. It holds the request for a period if it has no response to send it back. It regularly updates clients with new information like updating a status, processed chunks every minute with new data.</li> <li>SSEs are the best options when the server generates the data in a loop and sends multiple events to the clients and if we need real-time traffic from the server to the client.</li> </ul>"},{"location":"frontend/frontend_docs/#project-structure","title":"Project Structure","text":"<pre><code>.\n\u251c\u2500\u2500 API \n\u251c\u2500\u2500 Assets\n\u251c\u2500\u2500 Components \n\u2502   \u251c\u2500\u2500 ChatBot\n\u2502   \u2502   \u251c\u2500\u2500 Chatbot\n\u2502   \u2502   \u251c\u2500\u2500 ChatInfoModal\n\u2502   \u2502   \u251c\u2500\u2500 ChatModesSwitch\n\u2502   \u2502   \u251c\u2500\u2500 ChatModeToggle\n\u2502   \u2502   \u251c\u2500\u2500 ChatOnlyComponent\n\u2502   \u2502   \u251c\u2500\u2500 ChatInfo\n\u2502   \u2502   \u251c\u2500\u2500 CommonChatActions\n\u2502   \u2502   \u251c\u2500\u2500 CommunitiesInfo\n\u2502   \u2502   \u251c\u2500\u2500 EntitiesInfo\n\u2502   \u2502   \u251c\u2500\u2500 ExpandedChatButtonContainer\n\u2502   \u2502   \u251c\u2500\u2500 MetricsCheckbox\n\u2502   \u2502   \u251c\u2500\u2500 MetricsTab\n\u2502   \u2502   \u251c\u2500\u2500 MultiModeMetrics\n\u2502   \u2502   \u2514\u2500\u2500 SourcesInfo\n\u2502   \u251c\u2500\u2500 Data Sources\n\u2502   \u2502   \u251c\u2500\u2500 AWS\n\u2502   \u2502   \u251c\u2500\u2500 GCS\n\u2502   \u2502   \u251c\u2500\u2500 Local\n\u2502   \u2502   \u2514\u2500\u2500 Web\n\u2502   \u2502       \u2514\u2500\u2500 WebButton\n\u2502   \u251c\u2500\u2500 Graph\n\u2502   \u2502   \u251c\u2500\u2500 CheckboxSelection\n\u2502   \u2502   \u251c\u2500\u2500 GraphPropertiesPanel\n\u2502   \u2502   \u251c\u2500\u2500 GraphPropertiesTable\n\u2502   \u2502   \u251c\u2500\u2500 GraphViewButton\n\u2502   \u2502   \u251c\u2500\u2500 GraphViewModal\n\u2502   \u2502   \u251c\u2500\u2500 LegendsChip\n\u2502   \u2502   \u251c\u2500\u2500 ResizePanel\n\u2502   \u2502   \u2514\u2500\u2500 ResultOverview\n\u2502   \u251c\u2500\u2500 Layout\n\u2502   \u2502   \u251c\u2500\u2500 AlertIcon\n\u2502   \u2502   \u251c\u2500\u2500 DrawerChatbot\n\u2502   \u2502   \u251c\u2500\u2500 DrawerDropzone\n\u2502   \u2502   \u251c\u2500\u2500 Header\n\u2502   \u2502   \u251c\u2500\u2500 PageLayout\n\u2502   \u2502   \u2514\u2500\u2500 SideNav\n\u2502   \u251c\u2500\u2500 Popups\n\u2502   \u2502   \u251c\u2500\u2500 ChunkPopUp\n\u2502   \u2502   \u251c\u2500\u2500 ConnectionModal\n\u2502   \u2502   \u251c\u2500\u2500 DeletePopup\n\u2502   \u2502   \u251c\u2500\u2500 GraphEnhancementDialog\n\u2502   \u2502   \u251c\u2500\u2500 LargeFilePopup\n\u2502   \u2502   \u251c\u2500\u2500 RetryConfirmation\n\u2502   \u2502   \u2514\u2500\u2500 Settings\n\u2502   \u251c\u2500\u2500 UI\n\u2502   \u2502   \u251c\u2500\u2500 Alert\n\u2502   \u2502   \u251c\u2500\u2500 ButtonWithTooltip\n\u2502   \u2502   \u251c\u2500\u2500 BreakDownPopOver\n\u2502   \u2502   \u251c\u2500\u2500 CustomButton\n\u2502   \u2502   \u251c\u2500\u2500 CustomCheckBox\n\u2502   \u2502   \u251c\u2500\u2500 CustomMenu\n\u2502   \u2502   \u251c\u2500\u2500 CustomPopOver\n\u2502   \u2502   \u251c\u2500\u2500 CustomProgressBar\n\u2502   \u2502   \u251c\u2500\u2500 DatabaseIcon\n\u2502   \u2502   \u251c\u2500\u2500 DatabaseStatusIcon\n\u2502   \u2502   \u251c\u2500\u2500 Dropdown\n\u2502   \u2502   \u251c\u2500\u2500 ErrorBoundary\n\u2502   \u2502   \u251c\u2500\u2500 FallBackDialog\n\u2502   \u2502   \u251c\u2500\u2500 HoverableLink\n\u2502   \u2502   \u251c\u2500\u2500 IconButtonTooltip\n\u2502   \u2502   \u251c\u2500\u2500 Legend\n\u2502   \u2502   \u251c\u2500\u2500 ScienceMolecule\n\u2502   \u2502   \u251c\u2500\u2500 ShowAll\n\u2502   \u2502   \u2514\u2500\u2500 TipWrapper\n\u2502   \u251c\u2500\u2500 Websources\n\u2502   \u2502   \u251c\u2500\u2500 Web\n\u2502   \u2502   \u251c\u2500\u2500 Wikipedia\n\u2502   \u2502   \u251c\u2500\u2500 Youtube\n\u2502   \u2502   \u251c\u2500\u2500 CustomSourceInput\n\u2502   \u2502   \u251c\u2500\u2500 GenericSourceButton\n\u2502   \u2502   \u2514\u2500\u2500 GenericSourceModal\n\u2502   \u251c\u2500\u2500 Content\n\u2502   \u251c\u2500\u2500 FileTable\n\u2502   \u2514\u2500\u2500 QuickStarter\n\u251c\u2500\u2500 HOC\n\u2502   \u251c\u2500\u2500 CustomModal\n\u2502   \u2514\u2500\u2500 withVisibility\n\u251c\u2500\u2500 Assets\n\u2502   \u251c\u2500\u2500 images\n\u2502   \u2502   \u2514\u2500\u2500 Application Images\n\u2502   \u251c\u2500\u2500 chatbotMessages.json\n\u2502   \u2514\u2500\u2500 schema.json\n\u251c\u2500\u2500 Context\n\u2502   \u251c\u2500\u2500 Alert\n\u2502   \u251c\u2500\u2500 ThemeWrapper\n\u2502   \u251c\u2500\u2500 UserCredentials\n\u2502   \u251c\u2500\u2500 UserMessages\n\u2502   \u2514\u2500\u2500 UserFiles\n\u251c\u2500\u2500 Hooks\n\u2502   \u251c\u2500\u2500 useSourceInput\n\u2502   \u251c\u2500\u2500 useSpeech\n\u2502   \u2514\u2500\u2500 useSSE\n\u251c\u2500\u2500 Services\n\u251c\u2500\u2500 Styling\n\u2502   \u2514\u2500\u2500 info\n\u251c\u2500\u2500 Utils\n\u2502   \u251c\u2500\u2500 constants\n\u2502   \u251c\u2500\u2500 FileAPI\n\u2502   \u251c\u2500\u2500 Loader\n\u2502   \u251c\u2500\u2500 Queue\n\u2502   \u251c\u2500\u2500 toats\n\u2502   \u2514\u2500\u2500 utils\n\u251c\u2500\u2500 App\n\u251c\u2500\u2500 index\n\u251c\u2500\u2500 main\n\u251c\u2500\u2500 router\n\u251c\u2500\u2500 types\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"frontend/frontend_docs/#application-features","title":"Application Features","text":""},{"location":"frontend/frontend_docs/#1-setup-and-installation","title":"1. Setup and Installation","text":"<ul> <li>Added Node.js with version v21.1.0 and npm on the development machine</li> <li>Install necessary dependencies by running <code>yarn install</code>, such as axios for making HTTP requests and others to interact with the graph</li> </ul>"},{"location":"frontend/frontend_docs/#2-connect-to-the-neo4j-aura-instance","title":"2. Connect to the Neo4j Aura instance","text":"<p>Created a connection modal by adding details including protocol, URI, database name, username, and password. Added a submit button that triggers an API: <code>/connect</code> and accepts params like uri, password, username and database to establish a connection to the Neo4j Aura instance. Handled the authentication and error scenarios appropriately, by displaying relevant messages. To check whether the backend connection is up and working we hit the API: <code>/health</code>. The user can now access both AURA DS and AURA DB instances.</p> <ul> <li>If GDS Connection is there icon is scientific molecule &gt; Graph enhancement model &gt; Post processing jobs &gt; gives user the leverage to check and uncheck the communities checkbox</li> <li>If AURA DB &gt; icon is database icon &gt; Graph enhancement model &gt; Post processing jobs &gt; communities checkbox is disabled</li> </ul> <p></p> <p>Aura DS Connection</p> <p></p> <p>Aura DB connection</p> <p></p> <p>ReadOnly User</p> <p></p> <p>User not connected</p> <p></p>"},{"location":"frontend/frontend_docs/#3-file-source-integration","title":"3. File Source Integration","text":"<p>Implemented various file source integrations including drag-and-drop, web sources search that includes YouTube video, Wikipedia link, Amazon S3 file access, and Google Cloud Storage (GCS) file access. This allows users to upload PDF files from local storage or directly from the integrated sources.</p> <p>The APIs are as follows:</p> <ul> <li><code>/source_list</code>: to fetch the list of files in the DB</li> </ul> <p></p> <ul> <li><code>/upload</code>: to upload files from Local</li> </ul> <p></p> <ul> <li><code>/url/scan</code>: to scan the link or sources of YouTube, Wikipedia, and Web Sources</li> </ul> <p></p> <ul> <li> <p><code>/url/scan</code>: to scan the files of S3 and GCS</p> </li> <li> <p>Add the respective Bucket URL, access key and secret key to access S3 files</p> </li> </ul> <p></p> <ol> <li>Add the respective Project ID, Bucket name, and folder to access GCS files</li> </ol> <p></p> <ol> <li>User gets a redirect to the authentication page to authenticate their google account</li> </ol> <p></p>"},{"location":"frontend/frontend_docs/#4-file-source-extraction","title":"4. File Source Extraction","text":"<ul> <li><code>/extract</code> to fetch the number of nodes and relationships created</li> <li>During Extraction the selected files or all files in 'New' state go into 'Processing' state and then 'Completed' state if there are no failures</li> </ul> <ol> <li>A file with status Completed has an option to be Reprocess with the following options:</li> </ol> <ol> <li>A file with status Failed/Cancelled has an option to be Reprocess with the following options:</li> </ol>"},{"location":"frontend/frontend_docs/#5-graph-generation","title":"5. Graph Generation","text":"<ul> <li><code>/graph_query</code>:</li> <li>Created a component for generating graphs based on the files in the table, to extract nodes and relationships</li> <li>When the user clicks on the Preview Graph or on the Table View icon the user can see that the graph model holds three options for viewing: Lexical Graph, Entity Graph and Knowledge Graph</li> <li>We utilized Neo4j's graph library to visualize the extracted nodes and relationships in the form of a graph query API: <code>/graph_query</code></li> <li>There are options for customizing the graph visualization such as layout algorithms [zoom in, zoom out, fit, refresh], node styling, relationship types</li> </ul> <p>Preview Graph</p> <p></p> <p>File Graph</p> <p></p> <p>Graph Types</p> <ol> <li>Document &amp; Chunk</li> </ol> <p></p> <ol> <li>Entities</li> </ol> <p></p> <ol> <li>Communities</li> </ol> <p></p> <ul> <li><code>/get_neighbours</code>: This API is used to retrieve the neighbor nodes of the given element id of the node</li> </ul> <p></p>"},{"location":"frontend/frontend_docs/#6-chatbot","title":"6. Chatbot","text":"<p>Created a Chatbot Component which has state variables to manage user input and chat messages. Once the user asks the question and clicks on the Ask button API: <code>/chatbot</code> is triggered to send user input to the backend and receive the response. The chat also has options for users to see more details about the chat, text to speech and copy the response.</p> <p>Chat Drawer View</p> <p></p> <p>Chat Modal View</p> <p></p> <ul> <li><code>/clear_chat_bot</code>: to clear the chat history which is saved in Neo4j DB</li> </ul> <p></p> <ul> <li><code>/chunk_entities</code>: to fetch the number of sources, entities and chunks</li> </ul> <p>Sources</p> <p></p> <p>Entities</p> <p></p> <p>Chunks</p> <p></p> <ul> <li><code>/metric</code>: The API responsible for a evaluating chatbot responses on the basis of different metrics such as faithfulness and answer relevancy. This utilises RAGAS library to calculate these metrics</li> </ul> <p></p> <ul> <li><code>/additional_metrics</code>: The API responsible for a evaluating chatbot responses on the basis of different metrics such as context entity recall, semantic score, rouge score. This reuqire additional ground truth to be supplied by user. This utilises RAGAS library to calculate these metrics</li> </ul> <p></p> <p>Chat Modes</p> <ul> <li>There are five modes Vector, Fulltext, Graph+Vector+Fulltext, Entity search+Vector, Graph+Vector+Fulltext that can be provided to the chat to retrieve the answers in Production environment</li> <li>There is one more mode Graph that can be provided to the chat to retrieve the answers in Development environment</li> <li>There is one more mode Global search+Vector+Fulltext that can be provided to the chat to retrieve the answers if aura instance is GDS</li> </ul> <p>1) In Production Environment</p> <p></p> <p>2) In Development Environment</p> <p></p>"},{"location":"frontend/frontend_docs/#7-graph-enhancement-settings","title":"7. Graph Enhancement Settings","text":"<p>Users can now set their own Schema for nodes and relations or can already be an existing schema</p> <ul> <li>Entity Extraction Settings:</li> </ul> <p></p> <ul> <li><code>/schema</code>: to fetch the existing schema that already exists in the db</li> </ul> <p></p> <ul> <li><code>/populate_graph_schema</code>: to fetch the schema from user entered document text</li> </ul> <p></p> <ul> <li>Additional Instructions:</li> </ul> <p></p> <ul> <li><code>/delete_unconnected_nodes</code>: to remove the lonely entities</li> </ul> <p></p> <ul> <li><code>/merge_duplicate_nodes</code>: to merge the duplicate entities</li> </ul> <p>1) to merge the duplicate entities</p> <p></p> <p>2) to get duplicate entities</p> <p></p> <ul> <li><code>/post_processing</code>: to fine-tune the knowledge graph for improved performance and deeper analysis</li> </ul> <p>1) When GDS instance</p> <p></p> <p>2) When Aura DB instance</p> <p></p>"},{"location":"frontend/frontend_docs/#8-application-options","title":"8. Application Options","text":"<ul> <li>LLM Model</li> </ul> <p>User can select desired LLM models</p> <p></p> <ul> <li>Documentation: User can navigate to the application overview : https://neo4j.com/labs/genai-ecosystem/llm-graph-builder/</li> </ul> <p></p> <ul> <li>GitHub Issues: User can navigate to the gitHub issues which are in developers bucket list : https://github.com/neo4j-labs/llm-graph-builder/issues</li> </ul> <p></p> <ul> <li>Dark/Light Mode: User can choose the application view : both in dark and light mode</li> </ul> <p>1) Dark</p> <p></p> <p>2) Light</p> <p></p> <ul> <li>Chat Only Mode</li> </ul> <p>User can also use the chat only feature by navigating to the url at: https://llm-graph-builder.neo4jlabs.com/chat-only to ask questions related to documents which have been completely processed. User is required to pass the login credentials to connect to the database</p>"},{"location":"frontend/frontend_docs/#9-file-table-options","title":"9. File Table Options","text":"<p>User can explore various features available for files in the table, including sorting, filtering, viewing as a graph, examining nodes and relationships, copying file details, and accessing chunks related to the file</p> <p>File Status</p> <p></p> <p>File Nodes</p> <p></p> <p>File Relationships</p> <p></p> <p>File Actions</p> <p>** Graph View</p> <p></p> <p>** Copy File Data</p> <p></p> <p>** Text Chunks</p> <p></p>"},{"location":"frontend/frontend_docs/#10-interface-design","title":"10. Interface Design","text":"<p>Designed a user-friendly interface that guides users through the process of connecting to Neo4j Aura, accessing file sources, uploading PDF files, and generating graphs</p> <ul> <li>Components: @neo4j-ndl/react</li> <li>Icons: @neo4j-ndl/react/icons</li> <li>Graph Visualization: @neo4j-nvl/react</li> <li>NVL: @neo4j-nvl/core</li> <li>CSS: Inline styling, tailwind CSS</li> </ul>"},{"location":"frontend/frontend_docs/#11-deployment","title":"11. Deployment","text":"<p>Followed best practices for optimizing performance and security of the deployed application</p> <ul> <li>Local Deployment:   ** Running through docker-compose   ** By default only OpenAI and Diffbot are enabled since Gemini requires extra GCP configurations   ** In your root folder, create a .env file with your OPENAI and DIFFBOT keys (if you want to use both),   ** By default, the input sources will be: Local files, Youtube, Wikipedia ,AWS S3 and Webpages. As this default config is applied:   ** By default,all of the chat modes will be available: vector, graph+vector and graph. If none of the mode is mentioned in the chat modes variable all modes will be available:   ** You can then run Docker Compose to build and start all components:</li> </ul>"},{"location":"frontend/frontend_docs/#sourceindent0","title":"[source,indent=0]","text":"<ul> <li>VITE_LLM_MODELS=\"\"</li> <li>VITE_REACT_APP_SOURCES=\"\"</li> <li>VITE_GOOGLE_CLIENT_ID=\"xxxx\"  [For Google GCS integration]</li> <li>VITE_CHAT_MODES=\"\"</li> <li>VITE_CHUNK_SIZE=5242880</li> <li>VITE_TIME_PER_PAGE=50</li> <li>VITE_LARGE_FILE_SIZE=5242880</li> <li>VITE_ENV=\"PROD\"/ 'DEV'</li> <li>VITE_BACKEND_API_URL=</li> <li>VITE_BLOOM_URL=</li> <li>VITE_BACKEND_PROCESSING_URL=</li> <li>VITE_LLM_MODELS_PROD=\"openai_gpt_4o,openai_gpt_4o_mini,diffbot,gemini_1.5_flash\"</li> <li>VITE_BATCH_SIZE=2</li> </ul> <ul> <li>Cloud Deployment:   ** To deploy the app install the gcloud cli , run the following command in the terminal specifically from frontend root folder.     *** gcloud run deploy      *** source location current directory &gt; Frontend     *** region : 32 [us-central 1]     *** Allow unauthenticated request : Yes</li> </ul>"},{"location":"frontend/frontend_docs/#12-api-reference","title":"12. API Reference","text":""},{"location":"frontend/frontend_docs/#1-connection-modal","title":"1) Connection Modal","text":""},{"location":"frontend/frontend_docs/#post-connect","title":"POST /connect","text":"<p>Neo4j database connection on frontend is done with this API</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> </ul>"},{"location":"frontend/frontend_docs/#2-backend-database-connection","title":"2) Backend Database connection","text":""},{"location":"frontend/frontend_docs/#post-backend_connection_configuation","title":"POST /backend_connection_configuation","text":"<p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> </ul>"},{"location":"frontend/frontend_docs/#3-upload-files-from-local","title":"3) Upload Files from Local","text":""},{"location":"frontend/frontend_docs/#post-upload","title":"POST /upload","text":"<p>The upload endpoint is designed to handle the uploading of large files by breaking them into smaller chunks. This method ensures that large files can be uploaded efficiently without overloading the server</p> <p>API Parameters :</p> <ul> <li><code>file</code>= File to be uploaded</li> <li><code>source_type</code>= Source of the file</li> </ul>"},{"location":"frontend/frontend_docs/#4-user-defined-schema","title":"4) User Defined Schema","text":""},{"location":"frontend/frontend_docs/#post-schema","title":"POST /schema","text":"<p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> </ul>"},{"location":"frontend/frontend_docs/#5-graph-schema-from-input-text","title":"5) Graph schema from Input Text","text":""},{"location":"frontend/frontend_docs/#post-populate_graph_schema","title":"POST /populate_graph_schema","text":"<p>The API is used to populate a graph schema based on the provided input text, model, and schema description flag</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>input_text</code>= Text to generate schema from</li> <li><code>model</code>= LLM model to use</li> <li><code>is_schema_description_checked</code>=A flag indicating whether the schema description should be considered.</li> </ul>"},{"location":"frontend/frontend_docs/#6-unstructured-sources","title":"6) Unstructured Sources","text":""},{"location":"frontend/frontend_docs/#post-urlscan","title":"POST /url/scan","text":"<p>Create Document node for other sources - s3 bucket, gcs bucket, wikipedia, youtube url and web pages</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>url</code>= URL to scan</li> <li><code>source_type</code>= Source of the file</li> </ul>"},{"location":"frontend/frontend_docs/#7-extration-of-nodes-and-relations-from-data","title":"7) Extration of Nodes and Relations from Data","text":""},{"location":"frontend/frontend_docs/#post-extract","title":"POST /extract","text":"<p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>source_types</code>= Source of the file</li> <li><code>language</code>=Language in which wikipedia content will be extracted</li> </ul>"},{"location":"frontend/frontend_docs/#8-get-list-of-sources","title":"8) Get list of sources","text":""},{"location":"frontend/frontend_docs/#get-sources_list","title":"GET /sources_list","text":"<p>List all sources (Document nodes) present in Neo4j graph database</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> </ul>"},{"location":"frontend/frontend_docs/#9-post-processing-after-graph-generation","title":"9) Post processing after graph generation","text":""},{"location":"frontend/frontend_docs/#post-post_processing","title":"POST /post_processing :","text":"<p>This API is called at the end of processing of whole document to get create k-nearest neighbor relations between similar chunks of document based on KNN_MIN_SCORE which is 0.8 by default and to drop and create a full text index on db labels</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>tasks</code>= List of tasks to perform</li> </ul>"},{"location":"frontend/frontend_docs/#10-chat-with-data","title":"10) Chat with Data","text":""},{"location":"frontend/frontend_docs/#post-chat_bot","title":"POST /chat_bot","text":"<p>The API responsible for a chatbot system designed to leverage multiple AI models and a Neo4j graph database, providing answers to user queries. It interacts with AI models from OpenAI and Google's Vertex AI and utilizes embedding models to enhance the retrieval of relevant information</p> <p>Components : </p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>query</code>= User query</li> <li><code>model</code>= LLM model to use</li> <li><code>mode</code>= Chat mode to use</li> <li><code>session_id</code>= Session ID used to maintain the history of chats during the user's connection</li> </ul>"},{"location":"frontend/frontend_docs/#11-get-entities-from-chunks","title":"11) Get entities from chunks","text":""},{"location":"frontend/frontend_docs/#postchunk_entities","title":"POST/chunk_entities","text":"<p>This API is used to  get the entities and relations associated with a particular chunk and chunk metadata</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>chunk_id</code>= ID of the chunk to get entities for</li> </ul>"},{"location":"frontend/frontend_docs/#12-clear-chat-history","title":"12) Clear chat history","text":""},{"location":"frontend/frontend_docs/#post-clear_chat_bot","title":"POST /clear_chat_bot","text":"<p>This API is used to clear the chat history which is saved in Neo4j DB</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>session_id</code> = User session id for QA chat</li> </ul>"},{"location":"frontend/frontend_docs/#13-view-graph-for-a-file","title":"13) View graph for a file","text":""},{"location":"frontend/frontend_docs/#post-graph_query","title":"POST /graph_query","text":"<p>This API is used to view graph for a particular file</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>document_names</code> = File name for which user wants to view graph</li> </ul>"},{"location":"frontend/frontend_docs/#14-get-neighbour-nodes","title":"14) Get neighbour nodes","text":""},{"location":"frontend/frontend_docs/#post-get_neighbours","title":"POST /get_neighbours","text":"<p>This API is used to retrive the neighbor nodes of the given element id of the node</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>elementId</code> = Element id of the node to retrive its neighbours</li> </ul>"},{"location":"frontend/frontend_docs/#15-sse-event-to-update-processing-status","title":"15) SSE event to update processing status","text":""},{"location":"frontend/frontend_docs/#get-update_extract_status","title":"GET /update_extract_status","text":"<p>The API provides a continuous update on the extraction status of a specified file. It uses Server-Sent Events (SSE) to stream updates to the client</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>source_types</code>= Source of the file</li> </ul>"},{"location":"frontend/frontend_docs/#16-delete-selected-documents","title":"16) Delete selected documents","text":""},{"location":"frontend/frontend_docs/#post-delete_document_and_entities","title":"POST /delete_document_and_entities","text":"<p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>source_types</code>= Source of the file</li> <li><code>deleteEntities</code>= Boolean value to check entities deletion is requested or not</li> </ul>"},{"location":"frontend/frontend_docs/#17-cancel-processing-job","title":"17) Cancel processing job","text":""},{"location":"frontend/frontend_docs/#postcancelled_job","title":"POST/cancelled_job","text":"<p>This API is responsible for cancelling an in process job</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>source_types</code>= Source of the file</li> </ul>"},{"location":"frontend/frontend_docs/#18-deletion-of-orpahn-nodes","title":"18) Deletion of orpahn nodes","text":""},{"location":"frontend/frontend_docs/#post-delete_unconnected_nodes","title":"POST /delete_unconnected_nodes","text":"<p>The API is used to delete unconnected entities from database</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>unconnected_entities_list</code>=selected entities list to delete of unconnected entities</li> </ul>"},{"location":"frontend/frontend_docs/#19-get-the-list-of-orphan-nodes","title":"19) Get the list of orphan nodes","text":""},{"location":"frontend/frontend_docs/#post-get_unconnected_nodes_list","title":"POST /get_unconnected_nodes_list","text":"<p>The API retrieves a list of nodes in the graph database that are not connected to any other nodes</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> </ul>"},{"location":"frontend/frontend_docs/#20-get-duplicate-nodes","title":"20) Get duplicate nodes","text":""},{"location":"frontend/frontend_docs/#post-get_duplicate_nodes","title":"POST /get_duplicate_nodes","text":"<p>The API is used to fetch duplicate entities from database</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> </ul>"},{"location":"frontend/frontend_docs/#21-merge-duplicate-nodes","title":"21) Merge duplicate nodes","text":""},{"location":"frontend/frontend_docs/#post-merge_duplicate_nodes","title":"POST /merge_duplicate_nodes","text":"<p>The API is used to merge duplicate entities from database selected by user</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>duplicate_nodes_list</code>= selected entities list to merge of with similar entities</li> </ul>"},{"location":"frontend/frontend_docs/#22-drop-and-create-vector-index","title":"22) Drop and create vector index","text":""},{"location":"frontend/frontend_docs/#post-drop_create_vector_index","title":"POST /drop_create_vector_index","text":"<p>The API is used to drop and create the vector index when vector index dimesion are different</p> <p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>isVectorIndexExist</code>= True or False based on whether vector index exist in database</li> </ul>"},{"location":"frontend/frontend_docs/#23-reprocessing-of-sources","title":"23) Reprocessing of sources","text":""},{"location":"frontend/frontend_docs/#post-retry_processing","title":"POST /retry_processing","text":"<p>API Parameters :</p> <ul> <li><code>uri</code>= Neo4j database URI</li> <li><code>username</code>= Neo4j database username</li> <li><code>password</code>= Neo4j database password</li> <li><code>database</code>= Neo4j database name</li> <li><code>source_types</code>= Source of the file</li> <li><code>retry_condition</code> = One of the above 3 conditions which is selected for reprocessing.</li> </ul>"},{"location":"frontend/frontend_docs/#13-conclusion","title":"13. Conclusion","text":"<p>In conclusion, this technical document outlines the process of building a React application with Neo4j Aura integration for graph database functionalities</p>"},{"location":"frontend/frontend_docs/#14-referral-links","title":"14. Referral Links","text":"<ul> <li>Dev env : https://dev-frontend-dcavk67s4a-uc.a.run.app/</li> <li>Staging env: https://staging-frontend-dcavk67s4a-uc.a.run.app/</li> <li>Prod env:  https://prod-frontend-dcavk67s4a-uc.a.run.app/</li> </ul>"}]}